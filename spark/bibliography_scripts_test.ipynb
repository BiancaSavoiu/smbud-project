{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U4ugBnQJt8dk",
    "outputId": "16695f04-6931-4395-dc6f-f1cc9a9af174"
   },
   "outputs": [],
   "source": [
    "# Dowloading pyspark\n",
    "#!pip install pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREPARE THE ENVIRONMENT, UPLOAD DATA, PREPROCESS DATA AND CREATE THE TABLES: Author, Paper, Affiliation, Book, Journal and Conference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/08 09:07:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# With sparkSession we create a connection to our database\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, ArrayType, TimestampType\n",
    "from pyspark.sql.functions import count, col, xxhash64, collect_list, explode, monotonically_increasing_id\n",
    "\n",
    "# Create an entry point to the PySpark Application\n",
    "spark = SparkSession.builder \\\n",
    "      .master(\"local\") \\\n",
    "      .appName(\"Bibliography\") \\\n",
    "      .getOrCreate()\n",
    "\n",
    "INPUT_FILE = \"bibliography.json\"\n",
    "OPTIONS = {'multiline': 'true', 'allowNumericLeadingZero': 'true','timestampFormat': \"yyyy-MM-dd'T'HH:mm:ss[.ZZZ'Z']\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- authorID: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      " |-- bio: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+--------------------+--------------------+\n",
      "|            authorID|              name|               email|                 bio|\n",
      "+--------------------+------------------+--------------------+--------------------+\n",
      "|53f3186fdabfae9a8...|   A. M. A. Hariri|a..m..a..hariride...|My name is A. M. ...|\n",
      "|53f3186fdabfae9a8...|    Matthew Prowse|matthew.prowsefb@...|My name is Matthe...|\n",
      "|53f31870dabfae9a8...|       Sui-ping Qi|sui-ping.qi19@gma...|My name is Sui-pi...|\n",
      "|53f31871dabfae9a8...|     Renato Fabbri|renato.fabbrib7@g...|My name is Renato...|\n",
      "|53f31873dabfae9a8...|   Joachim Schimpf|joachim.schimpf8a...|My name is Joachi...|\n",
      "|53f31874dabfae9a8...|    E. Di Bernardo|e..di.bernardo10@...|My name is E. Di ...|\n",
      "|53f31875dabfae9a8...|    Steven F. Roth|steven.f..roth46@...|My name is Steven...|\n",
      "|53f31878dabfae9a8...|      Nima Zahadat|nima.zahadat3d@gm...|My name is Nima Z...|\n",
      "|53f3187ddabfae9a8...|         Ke Fa Cen|ke.fa.cen23@gmail...|My name is Ke Fa ...|\n",
      "|53f31881dabfae9a8...|    Ricky Houghton|ricky.houghton97@...|My name is Ricky ...|\n",
      "|53f31881dabfae9a8...|Eduardo H. Ramirez|eduardo.h..ramire...|My name is Eduard...|\n",
      "|53f31883dabfae9a8...| Cassidy J. Curtis|cassidy.j..curtis...|My name is Cassid...|\n",
      "|53f31885dabfae9a8...|  Brian D. Koblenz|brian.d..koblenz4...|My name is Brian ...|\n",
      "|53f31887dabfae9a8...|        Guohua Wan|guohua.wanca@gmai...|My name is Guohua...|\n",
      "|53f3188adabfae9a8...|     Irineu Theiss|irineu.theissfe@g...|My name is Irineu...|\n",
      "|53f31892dabfae9a8...|     Derek Yip-Hoi|derek.yip-hoidd@g...|My name is Derek ...|\n",
      "|53f31892dabfae9a8...|     Soo-Hyung Kim|soo-hyung.kimf5@g...|My name is Soo-Hy...|\n",
      "|53f31893dabfae9a8...|      Harold Lorin|harold.lorin7c@gm...|My name is Harold...|\n",
      "|53f3189ddabfae9a8...|    J. Nagy-György|j..nagy-györgyf4@...|My name is J. Nag...|\n",
      "|53f3189ddabfae9a8...|    Roy Varshavsky|roy.varshavsky1d@...|My name is Roy Va...|\n",
      "+--------------------+------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#AUTHOR TABLE\n",
    "schemaAut = StructType(\n",
    "            [StructField('authors', ArrayType(StructType([\n",
    "                StructField('_id', StringType(), nullable = False),\n",
    "                StructField('name', StringType(), True),\n",
    "                StructField('email', StringType(), True),\n",
    "                StructField('bio', StringType(), True),\n",
    "                ])), True)\n",
    "            ])\n",
    "\n",
    "dfAut = spark.read.format('json').options(**OPTIONS).schema(schemaAut).json(INPUT_FILE)\n",
    "dfAut = dfAut.select(explode(dfAut.authors))\n",
    "dfAut = dfAut.withColumnRenamed(\"col\", \"authors\")\n",
    "dfAut = dfAut.filter(col(\"authors._id\") != \"null\").select(\"authors._id\",\"authors.name\",\"authors.email\", \"authors.bio\")\n",
    "dfAut = dfAut.withColumnRenamed(\"_id\", \"authorID\")\n",
    "dfAut = dfAut.dropDuplicates([\"authorID\"])\n",
    "dfAut.printSchema()\n",
    "dfAut.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- paperID: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- keywords: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- fos: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- references: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- page_start: integer (nullable = true)\n",
      " |-- page_end: integer (nullable = true)\n",
      " |-- lang: string (nullable = true)\n",
      " |-- doi: string (nullable = true)\n",
      " |-- url: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- abstract: string (nullable = true)\n",
      " |-- publication_type: string (nullable = true)\n",
      " |-- date: timestamp (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------+----+--------------------+--------------------+--------------------+----------------+-------------------+\n",
      "|             paperID|               title|            keywords|                 fos|          references|page_start|page_end|lang|                 doi|                 url|            abstract|publication_type|               date|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------+----+--------------------+--------------------+--------------------+----------------+-------------------+\n",
      "|53e99784b7602d970...|Using XML to Inte...|[internet, hyperm...|[xml base, world ...|[53e9adbdb7602d97...|       167|     172|  en|10.1109/CMPSAC.20...|[http://dx.doi.or...|The eXtensible Ma...|            Book|1974-09-13 06:34:29|\n",
      "|53e99784b7602d970...|               FCLOS|[molap, subsumpti...|[information syst...|[53e99ee0b7602d97...|       192|     220|  en|10.1016/j.datak.2...|[http://dx.doi.or...|Mobile online ana...|         Journal|1950-04-14 05:33:22|\n",
      "|53e99785b7602d970...|              Bhoomi|[icts, e governan...|[revenue, transpa...|[53e9b2ffb7602d97...|        20|      31|  en|10.1016/j.tele.20...|[http://dx.doi.or...|The emergence of ...|         Journal|1984-04-06 03:49:29|\n",
      "|53e9978ab7602d970...|                Laps|[health care, hom...|[health care, pop...|[573695936e3b1202...|       962|     976|  en|10.1016/j.ejor.20...|[http://dx.doi.or...|The health care s...|         Journal|1951-10-28 04:52:04|\n",
      "|53e9978db7602d970...|             Mindful|[meta learning, h...|[data science, ro...|[53e9b0c2b7602d97...|      3253|    3274|  en|10.1016/j.ins.200...|[http://dx.doi.or...|Common inductive ...|         Journal|1955-04-13 19:06:45|\n",
      "|53e9978db7602d970...|             MESHMdl|[tuple space, mob...|[middleware, mobi...|[53e99a49b7602d97...|       467|     487|  en|10.1016/j.pmcj.20...|[http://dx.doi.or...|Mobile ad hoc net...|         Journal|2009-09-23 09:35:36|\n",
      "|53e9978db7602d970...|               iCity|[irregular cellul...|[software tool, a...|[53e9ac54b7602d97...|       761|     773|  en|10.1016/j.envsoft...|[http://dx.doi.or...|The objective of ...|         Journal|2002-05-14 19:30:38|\n",
      "|53e9978db7602d970...|              Wisdom|[decision support...|[cognitive map, r...|[53e99b7eb7602d97...|       156|     171|  en|10.1016/j.ejor.20...|[http://dx.doi.or...|Many decision sup...|         Journal|1987-12-30 04:51:23|\n",
      "|53e99792b7602d970...|        SwissAnalyst|         [key words]|[computer science...|[5c795a6e4895d9cb...|       393|     406|  en|10.1007/1-4020-81...|                null|This paper introd...|      Conference|1991-03-30 19:52:33|\n",
      "|53e99792b7602d970...|Short-Term Traffi...|[considerable acc...|[spline mathemati...|[53e9b95bb7602d97...|       669|     675|  en|10.1109/FSKD.2008...|[http://dx.doi.or...|A promising traff...|      Conference|2020-03-15 04:13:40|\n",
      "|53e99792b7602d970...|An approach to fe...|[feature location...|[data mining, cau...|[53e9b6eeb7602d97...|        57|      68|  en|10.1016/j.jss.200...|[http://dx.doi.or...|This paper descri...|         Journal|2012-05-05 11:48:40|\n",
      "|53e99792b7602d970...|Nested Graph-Stru...|[nested graph str...|[adjacency matrix...|[53e9b049b7602d97...|         1|      12|  en|  10.1007/BFb0056317|[http://dx.doi.or...|This paper descri...|            Book|1965-07-21 08:40:34|\n",
      "|53e99792b7602d970...|Demo: Yalut -- us...|[cellular data tr...|[world wide web, ...|[53e9b04eb7602d97...|       360|     361|  en|10.1145/2594368.2...|[http://dx.doi.or...|Yalut is a novel ...|      Conference|2009-02-24 08:00:34|\n",
      "|53e99792b7602d970...|A Uniform Paralle...|[knowledge discov...|[data mining, dat...|[53e99cbbb7602d97...|       306|     312|  en|10.1007/978-3-540...|[http://dx.doi.or...|Grid is a new sol...|         Journal|2015-02-28 22:51:57|\n",
      "|53e99792b7602d970...|WAVELET-BASED IMA...|[mathematical mod...|[computer vision,...|[53e9b550b7602d97...|      1737|    1740|  en|10.1109/ICIP.2010...|[http://dx.doi.or...|Because digital i...|      Conference|2005-12-16 23:43:26|\n",
      "|53e99792b7602d970...|A fuzzy multi-obj...|[location, fire s...|[objective progra...|[53e9bd50b7602d97...|       903|     915|  en|10.1016/j.ejor.20...|[http://dx.doi.or...|Location of fire ...|         Journal|1971-12-17 16:55:38|\n",
      "|53e99792b7602d970...|Adaptive presenta...|[evolving informa...|[metadata, progra...|[53e9a2c8b7602d97...|       193|     196|  en|10.1109/ICALT.200...|[http://dx.doi.or...|The article descr...|            Book|2011-05-08 17:41:02|\n",
      "|53e99792b7602d970...|Testing the stabi...|[asymptotic justi...|[functional princ...|[53e9ace1b7602d97...|       352|     367|  en|10.1016/j.jmva.20...|[http://dx.doi.or...|The functional au...|         Journal|1984-05-13 13:56:58|\n",
      "|53e99792b7602d970...|Statistical Prope...|[power cables, po...|[topology, trippi...|[53e9a7ddb7602d97...|      2517|    2526|  en|10.1109/HICSS.201...|[http://dx.doi.or...|We present the sy...|      Conference|2018-08-18 19:58:00|\n",
      "|53e99792b7602d970...|Generating novel ...|[adaptive behavio...|[interactive evol...|[53e9bc80b7602d97...|         8|      14|  en|10.1145/1056754.1...|[http://dx.doi.or...|Simulated evoluti...|         Journal|2021-05-05 05:11:38|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------+----+--------------------+--------------------+--------------------+----------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# PAPER TABLE WITHOUT PUBLICATION_ID\n",
    "schemaPaper = StructType(\n",
    "            [StructField('_id', StringType(), True),\n",
    "             StructField('title', StringType(),True),\n",
    "             StructField('keywords', ArrayType(StringType()), True),\n",
    "             StructField('fos', ArrayType(StringType()), True),\n",
    "             StructField('references', ArrayType(StringType()), True),\n",
    "             StructField('page_start', IntegerType(), True),\n",
    "             StructField('page_end', IntegerType(), True),\n",
    "             StructField('lang', StringType(),True),\n",
    "             StructField('doi', StringType(),True),\n",
    "             StructField('url', ArrayType(StringType()),True),\n",
    "             StructField('abstract', StringType(),True),\n",
    "             StructField('publication_type', StringType(),True),\n",
    "             StructField('date', TimestampType(), True)\n",
    "            ])\n",
    "\n",
    "dfPaper = spark.read.format('json').options(**OPTIONS).schema(schemaPaper).json(INPUT_FILE)\n",
    "dfPaper = dfPaper.withColumnRenamed(\"_id\", \"paperID\")\n",
    "dfPaper.printSchema()\n",
    "dfPaper.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- paperID: string (nullable = true)\n",
      " |-- authorID: string (nullable = true)\n",
      " |-- organization: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|             paperID|            authorID|        organization|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|53e998c7b7602d970...|53f3186fdabfae9a8...|Department of Sta...|\n",
      "|53e99827b7602d970...|53f3186fdabfae9a8...|Laboratory for Fo...|\n",
      "|53e99924b7602d970...|53f31870dabfae9a8...|Henan Academy of ...|\n",
      "|53e998dbb7602d970...|53f31871dabfae9a8...|Instituto de Físi...|\n",
      "|53e998f6b7602d970...|53f31873dabfae9a8...|                null|\n",
      "|53e998bfb7602d970...|53f31874dabfae9a8...|                null|\n",
      "|53e9984bb7602d970...|53f31875dabfae9a8...|                null|\n",
      "|53e998e8b7602d970...|53f31878dabfae9a8...|George Mason Univ...|\n",
      "|53e99905b7602d970...|53f3187ddabfae9a8...|State Key Laborat...|\n",
      "|53e998e9b7602d970...|53f31881dabfae9a8...|                null|\n",
      "|53e9984fb7602d970...|53f31881dabfae9a8...|Tecnologico de Mo...|\n",
      "|53e9980eb7602d970...|53f31883dabfae9a8...|University of Was...|\n",
      "|53e997e9b7602d970...|53f31885dabfae9a8...|Digital Equipment...|\n",
      "|53e998b0b7602d970...|53f31887dabfae9a8...|Antai College of ...|\n",
      "|53e998cdb7602d970...|53f31887dabfae9a8...|Department of Ind...|\n",
      "|53e998f0b7602d970...|53f3188adabfae9a8...|E-Gov, Juridical ...|\n",
      "|53e998fcb7602d970...|53f31892dabfae9a8...|2250 G G Brown, A...|\n",
      "|53e99998b7602d970...|53f31892dabfae9a8...|Chonnam National ...|\n",
      "|53e99800b7602d970...|53f31893dabfae9a8...|IBM Systems Resea...|\n",
      "|53e99866b7602d970...|53f3189ddabfae9a8...|Department of Mat...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# AFFILIATION TABLE\n",
    "schemaAffiliation = StructType(\n",
    "            [StructField('_id', StringType(), True),\n",
    "             StructField('authors', ArrayType(StructType([\n",
    "                    StructField('_id', StringType(), True),\n",
    "                    StructField('org', StringType(), True)\n",
    "             ])), True),\n",
    "            ])\n",
    "\n",
    "dfAff = spark.read.format('json').options(**OPTIONS).schema(schemaAffiliation).json(INPUT_FILE)\n",
    "dfAff = dfAff.withColumnRenamed(\"_id\", \"paperID\")\n",
    "dfAff = dfAff.select(\"paperID\", explode(dfAff.authors))\n",
    "dfAff = dfAff.withColumnRenamed(\"col\", \"authors\")\n",
    "dfAff = dfAff.filter(col(\"authors._id\") != \"null\").filter(col(\"paperID\") != \"null\").select(\"paperID\", \"authors._id\",\"authors.org\")\n",
    "dfAff = dfAff.withColumnRenamed(\"_id\", \"authorID\")\n",
    "dfAff = dfAff.dropDuplicates([\"authorID\", \"paperID\"])\n",
    "dfAff = dfAff.withColumnRenamed(\"org\", \"organization\")\n",
    "dfAff.printSchema()\n",
    "dfAff.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema of the books\n",
      "root\n",
      " |-- venue: string (nullable = true)\n",
      " |-- isbn: string (nullable = true)\n",
      " |-- publisher: string (nullable = true)\n",
      " |-- publication id: long (nullable = false)\n",
      "\n",
      "Books\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1025:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------+-------------+--------------------------------------------------+--------------------+\n",
      "|venue                                                                               |isbn         |publisher                                         |publication id      |\n",
      "+------------------------------------------------------------------------------------+-------------+--------------------------------------------------+--------------------+\n",
      "|ACM SIGSOFT Software Engineering Notes                                              |-159593-125-2|AGH University of Science and Technology          |-4146681027596907540|\n",
      "|Theor. Comput. Sci.                                                                 |0-0304-3975  |Elsevier                                          |-8641604748836216424|\n",
      "|ACL (Companion)                                                                     |0-111-456789 |Intellect Ltd.                                    |-1765624198251536382|\n",
      "|VLDB                                                                                |0-12-088469-0|The American Society of Mechanical Engineers(ASME)|-6546099223240010863|\n",
      "|Papers from the second workshop Vol. 13 on Human and Machine Vision II              |0-12-597345-4|SpringerOpen                                      |-5170613698490267273|\n",
      "|VLDB                                                                                |0-12-722442-4|Open Library of Humanities                        |5803877754064281982 |\n",
      "|Artif. Intell. Rev.                                                                 |0-13-176751-8|World Scientific Publishing Co. Pte Ltd           |-5191022792199354246|\n",
      "|SFCS '85 Proceedings of the 26th Annual Symposium on Foundations of Computer Science|0-13-652017-0|Elsevier                                          |4898287511903231544 |\n",
      "|CHI                                                                                 |0-201-30987-4|AGH University of Science and Technology          |4745093320936461129 |\n",
      "|Computer Human Interaction                                                          |0-201-30987-4|Brown University                                  |-3213114594400519435|\n",
      "|SIGGRAPH                                                                            |0-201-48560-5|Springer Science + Business Media                 |7678090193378385384 |\n",
      "|CHI                                                                                 |0-201-50932-6|Elsevier                                          |22285894483278744   |\n",
      "|Sigplan Notices                                                                     |0-201-53372-3|Elsevier                                          |127134876966261428  |\n",
      "|ISSAC                                                                               |0-201-54892-5|Taylor and Francis Ltd.                           |-1355898789984227595|\n",
      "|History of programming languages---II                                               |0-201-89502-1|Springer Verlag                                   |-2667848576388063536|\n",
      "|Neural Networks                                                                     |0-262-03188-4|Elsevier                                          |4141971837342876240 |\n",
      "|Computational Statistics                                                            |0-262-10076-2|Springer Science + Business Media                 |-619826641325096993 |\n",
      "|Symposium on Programming Language Implementation and Logic Programming              |0-262-19297-7|Elsevier                                          |6701520537364205852 |\n",
      "|AAAI                                                                                |0-262-51057-X|Tsinghua University Press                         |1804946402782986900 |\n",
      "|Artif. Intell.                                                                      |0-262-51091-X|Editorial and Publishing Board of JIG             |529998888475133215  |\n",
      "+------------------------------------------------------------------------------------+-------------+--------------------------------------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# BOOK TABLE\n",
    "# Preprocessing of the books for cleaning and merging the books\n",
    "book_schema_preprocessing = StructType(\n",
    "    [StructField('_id', StringType(), True),\n",
    "     StructField('isbn', StringType(), True),\n",
    "     StructField('publisher', StringType(), True),\n",
    "     StructField('venue', StringType(), True),\n",
    "     StructField('publication_type', StringType(),True)])\n",
    "\n",
    "# Reading the json file\n",
    "dfbooks_to_filter = spark.read.format('json').options(**OPTIONS).schema(book_schema_preprocessing).json(INPUT_FILE)\n",
    "\n",
    "# Filtering and adjusting the dataframe\n",
    "dfbooks_to_filter = dfbooks_to_filter.filter(col('publication_type') == 'Book').filter(col('isbn') != 'null').filter(col('venue') != 'null')\n",
    "dfbooks_to_filter = dfbooks_to_filter.groupBy('isbn', 'venue').agg(collect_list('publisher').alias('publishersArray'), collect_list('_id').alias('_id'), count(col('publisher'))) # count can be removed (I was interested in evaluating if the group by was meaningful)\n",
    "dfbooks_to_insert = dfbooks_to_filter.withColumn('publisher', dfbooks_to_filter['publishersArray'][0]).select('venue', 'isbn', 'publisher', '_id')\n",
    "\n",
    "# Adding the new column which is the id\n",
    "df_books = dfbooks_to_insert.withColumn('publication id', xxhash64('isbn', 'venue'))\n",
    "\n",
    "# Adding the foreign key to the papers\n",
    "exploded_books = df_books.select(explode('_id'), 'publication id')\n",
    "# exploded_books.show(truncate = False)\n",
    "\n",
    "df_papers_in_books = exploded_books.join(dfPaper, exploded_books.col == dfPaper.paperID)\n",
    "df_papers_in_books = df_papers_in_books.drop('col')\n",
    "\n",
    "df_books = df_books.drop(df_books._id)\n",
    "\n",
    "# Visualizing the data\n",
    "# print('Papers')\n",
    "# df_papers_in_books.show(truncate = False)\n",
    "print('Schema of the books')\n",
    "df_books.printSchema()\n",
    "print('Books')\n",
    "df_books.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema of the conferences\n",
      "root\n",
      " |-- venue: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- publication id: long (nullable = false)\n",
      "\n",
      "Conferences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1028:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------+--------------------------+--------------------+\n",
      "|venue                                                                                   |location                  |publication id      |\n",
      "+----------------------------------------------------------------------------------------+--------------------------+--------------------+\n",
      "|\"EDUCON                                                                                 |Moscow, Russia            |950373860555954453  |\n",
      "|2012 50TH ANNUAL ALLERTON CONFERENCE ON COMMUNICATION, CONTROL, AND COMPUTING (ALLERTON)|Dublin, Ireland           |-4245717996156385657|\n",
      "|2985415099                                                                              |Mexico City, Mexico       |-762166203857654039 |\n",
      "|2985532720                                                                              |Milan, Italy              |-7124098142925130015|\n",
      "|2987493177                                                                              |Osaka, Japan              |7551243357793819285 |\n",
      "|3D-GIS                                                                                  |London, UK                |1334491883820369589 |\n",
      "|3DIM                                                                                    |Johannesburg, South Africa|-1039299792543803944|\n",
      "|3DIMPVT                                                                                 |Helsinki, Finland         |-4577231382119670667|\n",
      "|3DOR                                                                                    |London, UK                |-8797854120325021263|\n",
      "|3DPVT                                                                                   |Amsterdam, Netherlands    |1375276120944605061 |\n",
      "|3DUI                                                                                    |Seoul, South Korea        |1791021788110955539 |\n",
      "|3DV                                                                                     |Jakarta, Indonesia        |3883608681790763346 |\n",
      "|3PGCIC                                                                                  |Beijing, China            |-3347673940037205862|\n",
      "|50 Years of Integer Programming                                                         |London, UK                |-5154516725105661246|\n",
      "|AAMAS                                                                                   |Milan, Italy              |5503995461761334696 |\n",
      "|AAMAS (2)                                                                               |Paris, France             |-7242857281816016648|\n",
      "|ACAI                                                                                    |Toronto, Canada           |8524679771896464283 |\n",
      "|ACC'09 Proceedings of the 2009 conference on American Control Conference                |Beijing, China            |-3525577454028830485|\n",
      "|ACCV                                                                                    |London, UK                |8287527867910422941 |\n",
      "|ACCV (1)                                                                                |Tel Aviv, Israel          |-2757184551560203638|\n",
      "+----------------------------------------------------------------------------------------+--------------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# CONFERENCE TABLE\n",
    "# Preprocessing of the books for cleaning and merging the books\n",
    "\n",
    "schemaConf = StructType(\n",
    "    [StructField('_id', StringType(), True),\n",
    "     StructField('location', StringType(), True),\n",
    "     StructField('venue', StringType(), True),\n",
    "     StructField('publication_type', StringType(),True)])\n",
    "# Reading the json file\n",
    "df_conferences_to_filter = spark.read.format('json').options(**OPTIONS).schema(schemaConf).json(INPUT_FILE)\n",
    "\n",
    "# Filtering and adjusting the dataframe\n",
    "df_conferences_to_filter = df_conferences_to_filter.filter(col('publication_type') == 'Conference').filter(col('venue') != 'null')\n",
    "df_conferences_to_filter = df_conferences_to_filter.groupBy('venue').agg(collect_list('location').alias('locations_array'), collect_list('_id').alias('_id'), count(col('location'))) # count can be removed (I was interested in evaluating if the group by was meaningful)\n",
    "df_conferences_to_insert = df_conferences_to_filter.withColumn('location', df_conferences_to_filter['locations_array'][0]).select('venue', 'location', '_id')\n",
    "\n",
    "# Adding the new column which is the id\n",
    "df_conferences = df_conferences_to_insert.withColumn('publication id', xxhash64('venue'))\n",
    "\n",
    "# Adding the foreign key to the papers\n",
    "exploded_conferences = df_conferences.select(explode('_id'), 'publication id')\n",
    "#exploded_conferences.show(truncate = False)\n",
    "\n",
    "df_papers_in_conferences = exploded_conferences.join(dfPaper, exploded_conferences.col == dfPaper.paperID)\n",
    "df_papers_in_conferences = df_papers_in_conferences.drop('col')\n",
    "\n",
    "df_conferences = df_conferences.drop(df_conferences._id)\n",
    "\n",
    "# Visualizing the data\n",
    "#print('Papers')\n",
    "#df_papers_in_conferences.show(truncate = False)\n",
    "print('Schema of the conferences')\n",
    "df_conferences.printSchema()\n",
    "print('Conferences')\n",
    "df_conferences.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Papers schema\n",
      "root\n",
      " |-- publication id: long (nullable = false)\n",
      " |-- paperID: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- keywords: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- fos: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- references: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- page_start: integer (nullable = true)\n",
      " |-- page_end: integer (nullable = true)\n",
      " |-- lang: string (nullable = true)\n",
      " |-- doi: string (nullable = true)\n",
      " |-- url: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- abstract: string (nullable = true)\n",
      " |-- publication_type: string (nullable = true)\n",
      " |-- date: timestamp (nullable = true)\n",
      "\n",
      "Papers data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------+----+--------------------+--------------------+--------------------+----------------+-------------------+\n",
      "|      publication id|             paperID|               title|            keywords|                 fos|          references|page_start|page_end|lang|                 doi|                 url|            abstract|publication_type|               date|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------+----+--------------------+--------------------+--------------------+----------------+-------------------+\n",
      "|-4336127124407324726|53e997d1b7602d970...|A fault diagnosis...|[stuck at defects...|[computer testing...|[53e9bca6b7602d97...|       494|     494|  en|10.1109/EDTC.1997...|[http://dx.doi.or...|In this paper we ...|            Book|1950-09-08 12:23:35|\n",
      "| 4674035537543784623|53e997e4b7602d970...|Problem Decomposi...|[problem decompos...|[inductive logic ...|[53e9a690b7602d97...|        17|      31|  en|10.1007/3-540-592...|[http://dx.doi.or...|One dimension of ...|            Book|1986-12-29 07:27:28|\n",
      "| 1144530160964015551|53e997e8b7602d970...|X-tract: Structur...|[information retr...|[information stru...|[53e9b0d8b7602d97...|         2|       2|  en|10.1109/SPIRE.199...|[http://computer....|Most available in...|            Book|1954-04-24 05:44:09|\n",
      "|-6465152039831803131|53e997e8b7602d970...|Cognitive agent p...|[dynamic logic, a...|[functional logic...|[53e9b38fb7602d97...|      1385|    1385|  en|10.1145/1082473.1...|[http://dx.doi.or...|This is a summary...|            Book|1992-05-16 17:49:48|\n",
      "| 5112790730981969721|53e997e9b7602d970...|Constraint based ...|[uniform framewor...|[computer science...|[53e9b326b7602d97...|       195|     204|  en|10.1145/318789.31...|[http://dx.doi.or...|The constraint tr...|            Book|1978-02-04 19:19:02|\n",
      "| 1369111316993402587|53e997ecb7602d970...|Automatic input r...|[google picasa, d...|[novel technique,...|[53e9a29db7602d97...|        80|      90|  en|10.1109/ICSE.2012...|[http://dx.doi.or...|We present a nove...|            Book|1971-08-25 11:47:59|\n",
      "| 1430384888819899512|53e997ecb7602d970...|Acceptability-ori...|[monitoring, acce...|[programming lang...|[53e9badfb7602d97...|        57|      75|  en|10.1145/966051.96...|[http://dx.doi.or...|We discuss a new ...|            Book|1964-08-09 22:48:00|\n",
      "|  710748220667054414|53e997ecb7602d970...|Anomalous Neighbo...|[column wise diff...|[mathematical opt...|[53e9a0a6b7602d97...|       474|     480|  en|10.1109/ICDMW.201...|[http://dx.doi.or...|We propose a meth...|            Book|1996-03-16 14:37:00|\n",
      "| 8148044123726554362|53e997f1b7602d970...|A Digital Watermark.|[authentication, ...|[computer vision,...|[53e99822b7602d97...|        86|      90|  en|10.1109/ICIP.1994...|[http://dx.doi.or...|This paper discus...|            Book|2001-12-04 20:38:24|\n",
      "|-8250923667053511275|53e997f4b7602d970...|Independent Tree ...|[independent tree...|[combinatorics, m...|[53e9b2f5b7602d97...|       203|     214|  en| 10.1007/10692760_17|[http://dx.doi.or...|\\n For any fixed ...|            Book|2014-02-26 04:06:46|\n",
      "| 8160813231728112221|53e997f5b7602d970...|Inverting onto fu...|[nondeterministic...|[computer science...|[53e9b4afb7602d97...|       213|     222|  en|10.1016/S0890-540...|[http://dx.doi.or...|We look at the hy...|            Book|2015-12-31 07:56:33|\n",
      "| 6712300784079919943|53e9980eb7602d970...|   EVES: An Overview|[never, formal me...|[programming lang...|[53e9a2bab7602d97...|       389|     405|  en|10.1007/3-540-548...|[http://dx.doi.or...|In this paper we ...|            Book|1972-08-07 17:35:34|\n",
      "|-1585425199704921662|53e99813b7602d970...|Distributed proba...|[error correction...|[binary pattern, ...|[53e99a67b7602d97...|      3398|    3401|  en|10.1109/ICASSP.20...|[http://dx.doi.or...|This paper introd...|            Book|2016-08-28 14:12:19|\n",
      "| 6134863903676584956|53e99818b7602d970...|Regulations by Va...|[power method, no...|[context sensitiv...|[53e9a946b7602d97...|       239|     248|  en|  10.1007/BFb0029967|[http://dx.doi.or...| . Valences are a...|            Book|1961-02-26 08:04:12|\n",
      "| 2530147181524079819|53e99818b7602d970...|Reflections on sy...|[object oriented,...|[communication de...|[53e99832b7602d97...|        28|      33|  en|10.1145/1556262.1...|[http://dx.doi.or...|Symmetry is routi...|            Book|2009-10-03 17:07:24|\n",
      "| 2735482298684145043|53e99827b7602d970...|Timestamping afte...|[committed transa...|[transaction proc...|[53e9b587b7602d97...|       160|     167|  en|10.1109/PDIS.1994...|[http://dx.doi.or...|Many applications...|            Book|1951-11-27 17:50:37|\n",
      "| 5744511372260825900|53e99827b7602d970...|The Animachine re...|[useful effect, v...|[3d computer grap...|[53e9ab2bb7602d97...|        90|      90|  en|10.1109/CA.1995.3...|[http://doi.ieeec...|Two-dimensional a...|            Book|2007-10-16 04:48:40|\n",
      "| 2483812910487536561|53e99827b7602d970...|     The CD1 system.|[advanced constra...|[sql, conceptual ...|[53e99967b7602d97...|         1|       9|  en|10.1007/978-3-642...|[http://dx.doi.or...|\\n We describe a ...|            Book|2013-03-31 03:16:37|\n",
      "| 8942054755879642437|53e9982cb7602d970...|Public-Key Regist...|[registration req...|[fixed access, cr...|[53e99a74b7602d97...|       451|     458|  en|10.1007/3-540-477...|[http://dx.doi.or...|A procedure is de...|            Book|1993-11-20 16:32:56|\n",
      "| 8730891231843712925|53e9983db7602d970...|Learning Automata...|[blue fringe edsm...|[quantum finite a...|[53e9afa6b7602d97...|        52|      65|  en|10.1007/978-3-642...|[http://dx.doi.or...|\\n We prove in th...|            Book|1960-12-16 13:42:14|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------+----+--------------------+--------------------+--------------------+----------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Merging the 3 dataframe which one contains the papers published in a specific media\n",
    "df_papers = df_papers_in_books.union(df_papers_in_journals).union(df_papers_in_conferences)\n",
    "\n",
    "# Visualizing the data\n",
    "print('Papers schema')\n",
    "df_papers.printSchema()\n",
    "print('Papers data')\n",
    "df_papers.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Papers published in books\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------------+--------------------+\n",
      "|             paperID|               title|publication_type|      publication id|\n",
      "+--------------------+--------------------+----------------+--------------------+\n",
      "|53e997d1b7602d970...|A fault diagnosis...|            Book|-4336127124407324726|\n",
      "|53e997e4b7602d970...|Problem Decomposi...|            Book| 4674035537543784623|\n",
      "|53e997e8b7602d970...|X-tract: Structur...|            Book| 1144530160964015551|\n",
      "|53e997e8b7602d970...|Cognitive agent p...|            Book|-6465152039831803131|\n",
      "|53e997e9b7602d970...|Constraint based ...|            Book| 5112790730981969721|\n",
      "|53e997ecb7602d970...|Automatic input r...|            Book| 1369111316993402587|\n",
      "|53e997ecb7602d970...|Acceptability-ori...|            Book| 1430384888819899512|\n",
      "|53e997ecb7602d970...|Anomalous Neighbo...|            Book|  710748220667054414|\n",
      "|53e997f1b7602d970...|A Digital Watermark.|            Book| 8148044123726554362|\n",
      "|53e997f4b7602d970...|Independent Tree ...|            Book|-8250923667053511275|\n",
      "|53e997f5b7602d970...|Inverting onto fu...|            Book| 8160813231728112221|\n",
      "|53e9980eb7602d970...|   EVES: An Overview|            Book| 6712300784079919943|\n",
      "|53e99813b7602d970...|Distributed proba...|            Book|-1585425199704921662|\n",
      "|53e99818b7602d970...|Regulations by Va...|            Book| 6134863903676584956|\n",
      "|53e99818b7602d970...|Reflections on sy...|            Book| 2530147181524079819|\n",
      "|53e99827b7602d970...|Timestamping afte...|            Book| 2735482298684145043|\n",
      "|53e99827b7602d970...|The Animachine re...|            Book| 5744511372260825900|\n",
      "|53e99827b7602d970...|     The CD1 system.|            Book| 2483812910487536561|\n",
      "|53e9982cb7602d970...|Public-Key Regist...|            Book| 8942054755879642437|\n",
      "|53e9983db7602d970...|Learning Automata...|            Book| 8730891231843712925|\n",
      "+--------------------+--------------------+----------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Papers published in journals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------------+--------------------+\n",
      "|             paperID|               title|publication_type|      publication id|\n",
      "+--------------------+--------------------+----------------+--------------------+\n",
      "|53e99915b7602d970...|A note on robust ...|         Journal|-8668689828003778653|\n",
      "|53e99984b7602d970...|A new approach fo...|         Journal|-6055461944651662439|\n",
      "|53e998b0b7602d970...|Two-machine flow ...|         Journal| 4482587362010925183|\n",
      "|53e9994cb7602d970...|Stochastic semide...|         Journal|-5369333412851545957|\n",
      "|53e9990db7602d970...|Models and algori...|         Journal| 4907811008184705540|\n",
      "|53e99952b7602d970...|Maximizing the mi...|         Journal|-7478992719207099405|\n",
      "|53e99800b7602d970...|Integer extended ...|         Journal|-5578571051264951046|\n",
      "|53e99858b7602d970...|Attraction probab...|         Journal| 3303577774132183121|\n",
      "|53e9998bb7602d970...|Strategy vs risk ...|         Journal|-3839102222582550984|\n",
      "|53e99915b7602d970...|A necessary 4-cyc...|         Journal|-8848711838540298032|\n",
      "|53e997f1b7602d970...|A retargetable de...|         Journal| 5898809803706162287|\n",
      "|53e997ddb7602d970...|Clustering with L...|         Journal|  226561117377407236|\n",
      "|53e99858b7602d970...|Weighted broadcas...|         Journal|-1537115915808707536|\n",
      "|53e997f4b7602d970...|Interactive topic...|         Journal| 6922825622688887655|\n",
      "|53e99991b7602d970...|Graphics Programm...|         Journal|-4352573166015971962|\n",
      "|53e99832b7602d970...|Program Transform...|         Journal| 7493946580737751003|\n",
      "|53e9984bb7602d970...|Voice response sy...|         Journal| 7340232518232887060|\n",
      "|53e9982cb7602d970...|Parallel graph al...|         Journal|-7713800651548746073|\n",
      "|53e99813b7602d970...|Dataflow machine ...|         Journal|-7000780314495031015|\n",
      "|53e997d1b7602d970...|Can there be a sc...|         Journal|-7255461002200856409|\n",
      "+--------------------+--------------------+----------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Papers published in conferences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------------+--------------------+\n",
      "|             paperID|               title|publication_type|      publication id|\n",
      "+--------------------+--------------------+----------------+--------------------+\n",
      "|53e99854b7602d970...|  The EOLES project.|      Conference|  950373860555954453|\n",
      "|53e9989bb7602d970...|Life is engineeri...|      Conference|  950373860555954453|\n",
      "|53e998bfb7602d970...|Gaining and maint...|      Conference|  950373860555954453|\n",
      "|53e998c0b7602d970...|From manuals towa...|      Conference|  950373860555954453|\n",
      "|53e998e9b7602d970...|Learning with com...|      Conference|  950373860555954453|\n",
      "|53e99976b7602d970...|Cloud E-learning ...|      Conference|  950373860555954453|\n",
      "|53e9997eb7602d970...|Motivating progra...|      Conference|  950373860555954453|\n",
      "|53e99991b7602d970...|Monitoring studen...|      Conference|  950373860555954453|\n",
      "|53e99998b7602d970...|OLAREX project: O...|      Conference|  950373860555954453|\n",
      "|53e99859b7602d970...|Studying dynamic ...|      Conference|-4245717996156385657|\n",
      "|53e99860b7602d970...|Equivalence of br...|      Conference|-4245717996156385657|\n",
      "|53e998bfb7602d970...|Fish Schools: PDE...|      Conference| -762166203857654039|\n",
      "|53e9997eb7602d970...|Automatic Generat...|      Conference|-7124098142925130015|\n",
      "|53e998fdb7602d970...|Fault-Tolerant Sc...|      Conference| 7551243357793819285|\n",
      "|53e9990db7602d970...|Automatic Generat...|      Conference| 1334491883820369589|\n",
      "|53e99822b7602d970...|Stroboscopic Ster...|      Conference|-1039299792543803944|\n",
      "|53e998bfb7602d970...|Image-Based Techn...|      Conference|-1039299792543803944|\n",
      "|53e9991cb7602d970...|Scanning and Proc...|      Conference|-1039299792543803944|\n",
      "|53e99940b7602d970...|Range Image Regis...|      Conference|-1039299792543803944|\n",
      "|53e99937b7602d970...|Cage-Based Motion...|      Conference|-4577231382119670667|\n",
      "+--------------------+--------------------+----------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For checking the result\n",
    "print('Papers published in books')\n",
    "df_papers.filter(col('publication_type') == 'Book').select('paperID', 'title', 'publication_type', 'publication id').show()\n",
    "print('Papers published in journals')\n",
    "df_papers.filter(col('publication_type') == 'Journal').select('paperID', 'title', 'publication_type', 'publication id').show()\n",
    "print('Papers published in conferences')\n",
    "df_papers.filter(col('publication_type') == 'Conference').select('paperID', 'title', 'publication_type', 'publication id').show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "COMMANDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Command 4: delete a group of rows\n",
    "\n",
    "# Use the function year to extract the year from the timestamp\n",
    "from pyspark.sql.functions import year\n",
    "\n",
    "# Drop rows with conditions – where clause\n",
    "# From 37626 to 37175 -> delete all the rows that represent papers published before 1950, because obsolete\n",
    "df_papers = df_papers.where(year('date') > '1950')\n",
    "df_papers.select('title', 'publication_type', 'date').orderBy('date').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Command 5: create a new column with the length of the paper (number of total pages)\n",
    "\n",
    "df_papers_total_pages = df_papers \\\n",
    "    .filter((col('page_start') >= 0) & (col('page_end') >= 0) & (col('page_start') <= col('page_end'))) \\\n",
    "    .withColumn('total_pages', col('page_end') - col('page_start'))\n",
    "\n",
    "df_papers_total_pages \\\n",
    "    .select(col('title'), col('page_start'), col('page_end'), col('total_pages')) \\\n",
    "    .show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "QUERIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Query 1: WHERE, JOIN\n",
    "# from pyspark.sql.functions import collect_list, size\n",
    "# \n",
    "# venue, volume, issue = ('IEEE Internet Computing', '5', '6') \n",
    "# \n",
    "# df_papers_q1 = df_journals\\\n",
    "#                 .filter((col('venue') == venue) &\n",
    "#                         (col('volume') == volume) &\n",
    "#                         (col('issue') == issue))\\\n",
    "#                 .join(df_papers.select(['paperID', 'publication id', 'publication_type', 'title']),\n",
    "#                       (df_journals['publication id'] == df_papers['publication id']) &\n",
    "#                         (df_papers['publication_type'] == 'Journal'),\n",
    "#                       'inner')\\\n",
    "#                 .groupBy(['venue', 'volume', 'issue'])\\\n",
    "#                 .agg(collect_list('title').alias('papers'))\\\n",
    "#                 .withColumn('papers', size(col('papers')))\n",
    "# \n",
    "# df_papers_q1.select(['papers']).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- paperID: string (nullable = true)\n",
      " |-- hash: long (nullable = false)\n",
      " |-- publication id: long (nullable = false)\n",
      " |-- publication_type: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- p2: string (nullable = true)\n",
      " |-- pub_join: long (nullable = false)\n",
      " |-- p1: string (nullable = true)\n",
      " |-- hash_join: long (nullable = false)\n",
      " |-- pubID?: boolean (nullable = false)\n",
      " |-- hashID?: boolean (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# JOURNAL TABLE\n",
    "# Preprocessing of the journals for cleaning and merging the journals\n",
    "\n",
    "journal_schema_preprocessing = StructType(\n",
    "    [StructField('_id', StringType(), True),\n",
    "     StructField('issn', StringType(), True),\n",
    "     StructField('publisher', StringType(), True),\n",
    "     StructField('venue', StringType(), True),\n",
    "     StructField('volume', IntegerType(), True),\n",
    "     StructField('issue', IntegerType(), True),\n",
    "     StructField('publication_type', StringType(),True)])\n",
    "\n",
    "# Reading the json file\n",
    "df_journals_to_filter = spark.read.format('json').options(**OPTIONS).schema(journal_schema_preprocessing).json(INPUT_FILE)\n",
    "\n",
    "# Filtering and adjusting the dataframe\n",
    "df_journals_to_filter = df_journals_to_filter\\\n",
    "                            .filter(col('publication_type') == 'Journal')\\\n",
    "                            .filter(col('issn') != 'null')\\\n",
    "                            .filter(col('venue') != 'null')\\\n",
    "                            .filter(col('issue') >= 0)\\\n",
    "                            .filter(col('volume') >= 0)\n",
    "\n",
    "df_journals_to_filter = df_journals_to_filter\\\n",
    "                            .groupBy('venue', 'volume', 'issue', 'issn')\\\n",
    "                            .agg(collect_list('publisher').alias('publishersArray'),\n",
    "                                 collect_list('_id').alias('_id'),\n",
    "                                 count(col('publisher'))) # count can be removed (I was interested in evaluating if the group by was meaningful)\n",
    "df_journals_to_insert = df_journals_to_filter\\\n",
    "                            .withColumn('publisher', df_journals_to_filter['publishersArray'][0])\\\n",
    "                            .select('venue', 'volume', 'issue', 'publisher', 'issn', '_id')\n",
    "\n",
    "# Adding the new column which contains the publication identifier\n",
    "df_journals = df_journals_to_insert.withColumn(\"publication id\", xxhash64('venue', 'volume', 'issue', 'issn'))\n",
    "df_journals2 = df_journals_to_insert.withColumn(\"publication id\", monotonically_increasing_id())\n",
    "\n",
    "df_journals4 = df_journals_to_insert.withColumns({'hash': xxhash64('venue', 'volume', 'issue', 'issn'),\n",
    "                                                  'publication id': monotonically_increasing_id()})\n",
    "\n",
    "# df_journals.printSchema()\n",
    "# Adding the foreign key to the papers\n",
    "exploded_journals = df_journals.select(explode('_id'), 'publication id')\n",
    "exploded_journals2 = df_journals2.select(explode('_id').alias('pID'), 'publication id')\n",
    "exploded_journals4 = df_journals4.select(explode('_id').alias('pID'), 'publication id', 'hash')\n",
    "#exploded_journals.show(truncate = False)\n",
    "\n",
    "df_papers_in_journals = exploded_journals.join(dfPaper, exploded_journals.col == dfPaper.paperID, \"inner\")\n",
    "df_papers_in_journals = df_papers_in_journals.drop('col')\n",
    "\n",
    "df_papers_in_journals2 = exploded_journals2\\\n",
    "                            .join(dfPaper, exploded_journals2.pID == dfPaper.paperID, \"inner\")\n",
    "df_papers_in_journals2 = df_papers_in_journals2.drop('pID')\n",
    "\n",
    "df_papers_in_journals4 = exploded_journals4\\\n",
    "                            .join(dfPaper, exploded_journals4.pID == dfPaper.paperID, \"inner\")\n",
    "df_papers_in_journals4 = df_papers_in_journals4.drop('pID')\n",
    "\n",
    "df_journals3 = df_journals.withColumn('hash', col('publication id')).drop('publication id').drop('_id')\\\n",
    "                            .join(df_journals2.drop('publisher'),\n",
    "                                  ['venue', 'volume', 'issue', 'issn'],\n",
    "                                 'inner')\n",
    "\n",
    "# df_journals3.printSchema()\n",
    "exploded_journals3 = df_journals3.select(explode('_id').alias('pID'), 'publication id', 'hash')\n",
    "\n",
    "df_papers_in_journals3 = exploded_journals3\\\n",
    "                            .join(dfPaper, exploded_journals3.pID == dfPaper.paperID, \"inner\")\n",
    "\n",
    "df_papers_in_journals3.drop('pID')\n",
    "all_papers = df_papers_in_journals3\\\n",
    "                .select(['paperID', 'hash', 'publication id', 'publication_type', 'title'])\\\n",
    "                .join(df_papers_in_journals2.select(col('paperID').alias('p2'), col('publication id').alias('pub_join')),\n",
    "                      df_papers_in_journals3.paperID == col('p2'))\\\n",
    "                .join(df_papers_in_journals.select(col('paperID').alias('p1'), col('publication id').alias('hash_join')),\n",
    "                      df_papers_in_journals3.paperID == col('p1'))\n",
    "\n",
    "stats = all_papers.withColumn('pubID?', col('publication id') == col('pub_join'))\\\n",
    "                  .withColumn('hashID?', col('hash') == col('pub_join'))\n",
    "\n",
    "stats.printSchema()\n",
    "\n",
    "\n",
    "df_journals = df_journals.drop(df_journals._id)\n",
    "df_journals2 = df_journals2.drop('_id')\n",
    "df_journals4 = df_journals4.drop('_id')\n",
    "# Visualizing the data\n",
    "# print('Papers')\n",
    "# df_papers_in_journals.show(truncate = False)\n",
    "# print('Schema of the journals')\n",
    "# df_papers_in_journals.printSchema()\n",
    "# df_journals.printSchema()\n",
    "# print('Journals')\n",
    "# df_journals.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|count((pubID? = true))|\n",
      "+----------------------+\n",
      "|                 13708|\n",
      "+----------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+\n",
      "|count((hashID? = true))|\n",
      "+-----------------------+\n",
      "|                  13708|\n",
      "+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp = stats.agg(count(col('pubID?') == True))\n",
    "tmp.show()\n",
    "tmp = stats.agg(count(col('hashID?') == True))\n",
    "tmp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11270\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11270\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11270\n",
      "4 mon_inc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11270\n",
      "4 hash\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11270\n",
      "Papers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 898:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(df_journals.count())\n",
    "print(df_journals.drop_duplicates(['publication id']).count())\n",
    "\n",
    "print('2')\n",
    "print(df_journals2.count())\n",
    "print(df_journals2.drop_duplicates(['publication id']).count())\n",
    "\n",
    "print('3')\n",
    "print(df_journals3.count())\n",
    "print(df_journals3.drop_duplicates(['publication id', 'hash']).count())\n",
    "\n",
    "print('4 mon_inc')\n",
    "print(df_journals4.count())\n",
    "print(df_journals4.drop_duplicates(['publication id']).count())\n",
    "\n",
    "print('4 hash')\n",
    "print(df_journals4.count())\n",
    "print(df_journals4.drop_duplicates(['hash']).count())\n",
    "\n",
    "print('Papers')\n",
    "print(df_papers_in_journals.count())\n",
    "print(df_papers_in_journals2.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1003:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "keys = df_papers_in_journals4.select('publication id', 'hash').dropDuplicates()\n",
    "print(keys.count())\n",
    "jkeys = df_journals4.select('publication id', 'hash').dropDuplicates()\n",
    "print(jkeys.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- venue: string (nullable = true)\n",
      " |-- volume: integer (nullable = true)\n",
      " |-- issue: integer (nullable = true)\n",
      " |-- publisher: string (nullable = true)\n",
      " |-- issn: string (nullable = true)\n",
      " |-- hash: long (nullable = false)\n",
      " |-- publication id: long (nullable = false)\n",
      "\n",
      "root\n",
      " |-- venue: string (nullable = true)\n",
      " |-- volume: integer (nullable = true)\n",
      " |-- issue: integer (nullable = true)\n",
      " |-- publisher: string (nullable = true)\n",
      " |-- issn: string (nullable = true)\n",
      " |-- publication id: long (nullable = false)\n",
      "\n",
      "root\n",
      " |-- publication id: long (nullable = false)\n",
      " |-- hash: long (nullable = false)\n",
      " |-- paperID: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- keywords: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- fos: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- references: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- page_start: integer (nullable = true)\n",
      " |-- page_end: integer (nullable = true)\n",
      " |-- lang: string (nullable = true)\n",
      " |-- doi: string (nullable = true)\n",
      " |-- url: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- abstract: string (nullable = true)\n",
      " |-- publication_type: string (nullable = true)\n",
      " |-- date: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "papers = df_papers_in_journals4\n",
    "journals = df_journals4\n",
    "\n",
    "journals.printSchema()\n",
    "df_journals.printSchema()\n",
    "papers.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+-----+------+\n",
      "|                name|volume|issue|papers|\n",
      "+--------------------+------+-----+------+\n",
      "|  BMC Bioinformatics|     7|    1|    18|\n",
      "|  BMC Bioinformatics|     9|    1|    16|\n",
      "|  BMC Bioinformatics|    11|    1|    13|\n",
      "|  BMC Bioinformatics|     6|    1|    12|\n",
      "|  BMC Bioinformatics|     8|    1|    11|\n",
      "|   ACM Trans. Graph.|    27|    3|    10|\n",
      "|  BMC Bioinformatics|    10|    1|     9|\n",
      "|  BMC Bioinformatics|    14|    1|     9|\n",
      "| BMC systems biology|     6|    1|     9|\n",
      "|  Expert Syst. Appl.|    39|    1|     8|\n",
      "|   ACM Trans. Graph.|    23|    3|     8|\n",
      "|   ACM Trans. Graph.|    24|    3|     8|\n",
      "|  BMC Bioinformatics|    12|    1|     8|\n",
      "|   ACM Trans. Graph.|    28|    5|     7|\n",
      "| BMC systems biology|     4|    1|     7|\n",
      "| BMC systems biology|     2|    1|     7|\n",
      "|  Expert Syst. Appl.|    39|    3|     7|\n",
      "|Procedia Computer...|     1|    1|     7|\n",
      "|  Expert Syst. Appl.|    39|    5|     7|\n",
      "|             SIGCOMM|    43|    4|     7|\n",
      "+--------------------+------+-----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import collect_list, size\n",
    "\n",
    "\n",
    "venue, volume, issue = ('IEEE Internet Computing', '5', '6') \n",
    "\n",
    "papers = df_papers_in_journals4\n",
    "journals = df_journals4\n",
    "df_papers_q1 = journals\\\n",
    "                .join(papers,\n",
    "                      ['hash'],\n",
    "                      'inner')\\\n",
    "                .groupBy('venue', 'volume', 'issue')\\\n",
    "                .agg(collect_list('title').alias('papers'))\\\n",
    "                .withColumn('papers', size(col('papers')))\\\n",
    "                .sort(col('papers').desc())\n",
    "\n",
    "df_papers_q1.select(col('venue').alias('name'), 'volume', 'issue', 'papers').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Query 4: GROUP BY, JOIN, AS\n",
    "from pyspark.sql.functions import collect_set, concat, size\n",
    "\n",
    "df_journals_venue_rename = df_journals.withColumnRenamed('venue', 'venueJournals')\n",
    "df_books_venue_rename = df_books.withColumnRenamed('venue', 'venueBooks')\n",
    "df = df_books_venue_rename\\\n",
    "    .join(df_journals_venue_rename,\n",
    "          df_books_venue_rename.publisher == df_journals_venue_rename.publisher,\n",
    "          \"inner\")\\\n",
    "    .drop(df_journals.publisher)\\\n",
    "    .select('venueBooks', 'venueJournals', 'publisher')\\\n",
    "    .dropDuplicates(['venueBooks', 'venueJournals', 'publisher'])\\\n",
    "    .groupBy('publisher')\\\n",
    "    .agg(collect_set('venueBooks').alias('books'),\n",
    "         collect_set('venueJournals').alias('journals'))\\\n",
    "    .withColumn(\"total_publications_per_publisher\",\n",
    "                concat(col(\"books\"), col(\"journals\")))\\\n",
    "    .filter(size(col(\"total_publications_per_publisher\")) > '500')\\\n",
    "    .select('publisher', \"total_publications_per_publisher\")\\\n",
    "    .show(truncate = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Query 5: WHERE, GROUP BY\n",
    "# Retrieve some statistics about papers\n",
    "from pyspark.sql.functions import sum, min, max, avg, format_number, variance\n",
    "\n",
    "df_papers_total_pages.filter(year(col('date')) >= 2015) \\\n",
    "    .groupBy(year(col('date')).alias('year')) \\\n",
    "    .agg(count('paperID').alias('total_papers'),\n",
    "         sum('total_pages').alias('total_pages'),\n",
    "         min('total_pages').alias('min_pages'),\n",
    "         max('total_pages').alias('max_pages'),\n",
    "         format_number(avg('total_pages'), 2).alias('avg_pages'),\n",
    "         format_number(variance('total_pages'), 2).alias('var_pages')) \\\n",
    "    .sort(col('year').desc()) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 6: GROUP BY, HAVING, AS\n",
    "df_papers_q6 = df_papers\\\n",
    "                    .select(['paperID', 'title', explode(col('references')).alias('reference')])\\\n",
    "                    .groupBy('reference')\\\n",
    "                    .agg(count('*').alias('references_count'))\\\n",
    "                    .filter(col('references_count') > 30)\\\n",
    "                    .join(df_papers.select(['paperID', 'title', 'doi', 'url']),\n",
    "                          col('reference') == df_papers.paperID)\\\n",
    "                    .sort(col('references_count').desc())\\\n",
    "\n",
    "df_papers_q6.select(['title', 'references_count']).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Query 9: WHERE, GROUP BY, HAVING, 1 JOIN\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Query 10: WHERE, GROUP BY, HAVING, 2 JOINs\n",
    "# Retrieve authors who worked for at least 3 different organizations and have published at least 3 papers with at least 5 fos and 5 references each\n",
    "\n",
    "from pyspark.sql.functions import approx_count_distinct\n",
    "\n",
    "df_papers \\\n",
    "    .filter((size(col('fos')) >= 5) & (size(col('references')) >= 5)) \\\n",
    "    .join(dfAff, df_papers.paperID == dfAff.paperID, \"inner\") \\\n",
    "    .drop(dfAff.paperID) \\\n",
    "    .join(dfAut, dfAff.authorID == dfAut.authorID, \"inner\") \\\n",
    "    .drop(dfAff.authorID) \\\n",
    "    .groupBy(\"authorID\") \\\n",
    "    .agg(count(\"paperID\").alias(\"papers_count\"),                                                                                       approx_count_distinct(\"organization\").alias(\"organizations_count\"),\n",
    "         collect_set(\"name\").alias(\"name\")) \\\n",
    "    .filter((size(\"name\") == 1) & (col(\"papers_count\") >= 3)  & (col(\"organizations_count\") >= 3)) \\\n",
    "    .orderBy(col(\"papers_count\").desc(), col(\"organizations_count\").desc()) \\\n",
    "    .select(explode(col(\"name\")).alias(\"name\"), col(\"papers_count\"), col(\"organizations_count\")) \\\n",
    "    .show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------+----------------+\n",
      "|title                                                            |references_count|\n",
      "+-----------------------------------------------------------------+----------------+\n",
      "|Distinctive Image Features from Scale-Invariant Keypoints        |196             |\n",
      "|A simple transmit diversity technique for wireless communications|62              |\n",
      "|Light field rendering                                            |56              |\n",
      "|Network information flow                                         |56              |\n",
      "|Symbolic Model Checking                                          |45              |\n",
      "|Mining Sequential Patterns                                       |44              |\n",
      "|Geodesic Active Contour.                                         |40              |\n",
      "|Differential Power Analysis                                      |38              |\n",
      "+-----------------------------------------------------------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_papers_q6 = df_papers\\\n",
    "                    .select('paperID',\n",
    "                            'title',\n",
    "                            explode(col('references')).alias('reference'))\\\n",
    "                    .groupBy('reference')\\\n",
    "                    .agg(count('paperID').alias('references_count'))\\\n",
    "                    .filter(col('references_count') > 30)\\\n",
    "                    .join(df_papers,\n",
    "                          col('reference') == df_papers.paperID)\\\n",
    "                    .sort(col('references_count').desc())\\\n",
    "\n",
    "df_papers_q6.select(['title', 'references_count']).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}