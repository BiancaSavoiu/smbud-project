{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U4ugBnQJt8dk",
    "outputId": "85f42e41-b3d2-4c1b-de49-56addeabdf0a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Dowloading pyspark\n",
    "#!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "PREPARE THE ENVIRONMENT, UPLOAD DATA, PREPROCESS DATA AND CREATE THE TABLES: Author, Paper, Affiliation, Book, Journal and Conference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# With sparkSession we create a connection to our database\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, ArrayType, TimestampType\n",
    "from pyspark.sql.functions import count, col, xxhash64, collect_list, explode\n",
    "\n",
    "# Create an entry point to the PySpark Application\n",
    "spark = SparkSession.builder \\\n",
    "      .master(\"local\") \\\n",
    "      .appName(\"Bibliography\") \\\n",
    "      .getOrCreate()\n",
    "\n",
    "#INPUT_FILE = \"/content/drive/MyDrive/bibliography.json\"\n",
    "INPUT_FILE = \"bibliography.json\"\n",
    "OPTIONS = {'multiline': 'true', 'allowNumericLeadingZero': 'true','timestampFormat': \"yyyy-MM-dd'T'HH:mm:ss[.ZZZ'Z']\"}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- author_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      " |-- bio: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+--------------------+--------------------+\n",
      "|           author_id|              name|               email|                 bio|\n",
      "+--------------------+------------------+--------------------+--------------------+\n",
      "|53f3186fdabfae9a8...|   A. M. A. Hariri|a..m..a..hariride...|My name is A. M. ...|\n",
      "|53f3186fdabfae9a8...|    Matthew Prowse|matthew.prowsefb@...|My name is Matthe...|\n",
      "|53f31870dabfae9a8...|       Sui-ping Qi|sui-ping.qi19@gma...|My name is Sui-pi...|\n",
      "|53f31871dabfae9a8...|     Renato Fabbri|renato.fabbrib7@g...|My name is Renato...|\n",
      "|53f31873dabfae9a8...|   Joachim Schimpf|joachim.schimpf8a...|My name is Joachi...|\n",
      "|53f31874dabfae9a8...|    E. Di Bernardo|e..di.bernardo10@...|My name is E. Di ...|\n",
      "|53f31875dabfae9a8...|    Steven F. Roth|steven.f..roth46@...|My name is Steven...|\n",
      "|53f31878dabfae9a8...|      Nima Zahadat|nima.zahadat3d@gm...|My name is Nima Z...|\n",
      "|53f3187ddabfae9a8...|         Ke Fa Cen|ke.fa.cen23@gmail...|My name is Ke Fa ...|\n",
      "|53f31881dabfae9a8...|    Ricky Houghton|ricky.houghton97@...|My name is Ricky ...|\n",
      "|53f31881dabfae9a8...|Eduardo H. Ramirez|eduardo.h..ramire...|My name is Eduard...|\n",
      "|53f31883dabfae9a8...| Cassidy J. Curtis|cassidy.j..curtis...|My name is Cassid...|\n",
      "|53f31885dabfae9a8...|  Brian D. Koblenz|brian.d..koblenz4...|My name is Brian ...|\n",
      "|53f31887dabfae9a8...|        Guohua Wan|guohua.wanca@gmai...|My name is Guohua...|\n",
      "|53f3188adabfae9a8...|     Irineu Theiss|irineu.theissfe@g...|My name is Irineu...|\n",
      "|53f31892dabfae9a8...|     Derek Yip-Hoi|derek.yip-hoidd@g...|My name is Derek ...|\n",
      "|53f31892dabfae9a8...|     Soo-Hyung Kim|soo-hyung.kimf5@g...|My name is Soo-Hy...|\n",
      "|53f31893dabfae9a8...|      Harold Lorin|harold.lorin7c@gm...|My name is Harold...|\n",
      "|53f3189ddabfae9a8...|    J. Nagy-György|j..nagy-györgyf4@...|My name is J. Nag...|\n",
      "|53f3189ddabfae9a8...|    Roy Varshavsky|roy.varshavsky1d@...|My name is Roy Va...|\n",
      "+--------------------+------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#AUTHOR TABLE\n",
    "schemaAut = StructType(\n",
    "            [StructField('authors', ArrayType(StructType([\n",
    "                StructField('_id', StringType(), nullable = False),\n",
    "                StructField('name', StringType(), True),\n",
    "                StructField('email', StringType(), True),\n",
    "                StructField('bio', StringType(), True),\n",
    "                ])), True)\n",
    "            ])\n",
    "\n",
    "df_aut = spark.read.format('json').options(**OPTIONS).schema(schemaAut).json(INPUT_FILE)\n",
    "df_aut = df_aut.select(explode(df_aut.authors))\n",
    "df_aut = df_aut.withColumnRenamed(\"col\", \"authors\")\n",
    "df_aut = df_aut.filter(col(\"authors._id\") != \"null\").select(\"authors._id\",\"authors.name\",\"authors.email\", \"authors.bio\")\n",
    "df_aut = df_aut.withColumnRenamed(\"_id\", \"author_id\")\n",
    "df_aut = df_aut.dropDuplicates([\"author_id\"])\n",
    "df_aut.printSchema()\n",
    "df_aut.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- paper_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- keywords: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- fos: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- references: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- page_start: integer (nullable = true)\n",
      " |-- page_end: integer (nullable = true)\n",
      " |-- lang: string (nullable = true)\n",
      " |-- doi: string (nullable = true)\n",
      " |-- url: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- abstract: string (nullable = true)\n",
      " |-- publication_type: string (nullable = true)\n",
      " |-- date: timestamp (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------+----+--------------------+--------------------+--------------------+----------------+-------------------+\n",
      "|            paper_id|               title|            keywords|                 fos|          references|page_start|page_end|lang|                 doi|                 url|            abstract|publication_type|               date|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------+----+--------------------+--------------------+--------------------+----------------+-------------------+\n",
      "|53e99784b7602d970...|Using XML to Inte...|[internet, hyperm...|[xml base, world ...|[53e9adbdb7602d97...|       167|     172|  en|10.1109/CMPSAC.20...|[http://dx.doi.or...|The eXtensible Ma...|            Book|1974-09-13 06:34:29|\n",
      "|53e99784b7602d970...|               FCLOS|[molap, subsumpti...|[information syst...|[53e99ee0b7602d97...|       192|     220|  en|10.1016/j.datak.2...|[http://dx.doi.or...|Mobile online ana...|         Journal|1950-04-14 05:33:22|\n",
      "|53e99785b7602d970...|              Bhoomi|[icts, e governan...|[revenue, transpa...|[53e9b2ffb7602d97...|        20|      31|  en|10.1016/j.tele.20...|[http://dx.doi.or...|The emergence of ...|         Journal|1984-04-06 03:49:29|\n",
      "|53e9978ab7602d970...|                Laps|[health care, hom...|[health care, pop...|[573695936e3b1202...|       962|     976|  en|10.1016/j.ejor.20...|[http://dx.doi.or...|The health care s...|         Journal|1951-10-28 04:52:04|\n",
      "|53e9978db7602d970...|             Mindful|[meta learning, h...|[data science, ro...|[53e9b0c2b7602d97...|      3253|    3274|  en|10.1016/j.ins.200...|[http://dx.doi.or...|Common inductive ...|         Journal|1955-04-13 19:06:45|\n",
      "|53e9978db7602d970...|             MESHMdl|[tuple space, mob...|[middleware, mobi...|[53e99a49b7602d97...|       467|     487|  en|10.1016/j.pmcj.20...|[http://dx.doi.or...|Mobile ad hoc net...|         Journal|2009-09-23 09:35:36|\n",
      "|53e9978db7602d970...|               iCity|[irregular cellul...|[software tool, a...|[53e9ac54b7602d97...|       761|     773|  en|10.1016/j.envsoft...|[http://dx.doi.or...|The objective of ...|         Journal|2002-05-14 19:30:38|\n",
      "|53e9978db7602d970...|              Wisdom|[decision support...|[cognitive map, r...|[53e99b7eb7602d97...|       156|     171|  en|10.1016/j.ejor.20...|[http://dx.doi.or...|Many decision sup...|         Journal|1987-12-30 04:51:23|\n",
      "|53e99792b7602d970...|        SwissAnalyst|         [key words]|[computer science...|[5c795a6e4895d9cb...|       393|     406|  en|10.1007/1-4020-81...|                null|This paper introd...|      Conference|1991-03-30 19:52:33|\n",
      "|53e99792b7602d970...|Short-Term Traffi...|[considerable acc...|[spline mathemati...|[53e9b95bb7602d97...|       669|     675|  en|10.1109/FSKD.2008...|[http://dx.doi.or...|A promising traff...|      Conference|2020-03-15 04:13:40|\n",
      "|53e99792b7602d970...|An approach to fe...|[feature location...|[data mining, cau...|[53e9b6eeb7602d97...|        57|      68|  en|10.1016/j.jss.200...|[http://dx.doi.or...|This paper descri...|         Journal|2012-05-05 11:48:40|\n",
      "|53e99792b7602d970...|Nested Graph-Stru...|[nested graph str...|[adjacency matrix...|[53e9b049b7602d97...|         1|      12|  en|  10.1007/BFb0056317|[http://dx.doi.or...|This paper descri...|            Book|1965-07-21 08:40:34|\n",
      "|53e99792b7602d970...|Demo: Yalut -- us...|[cellular data tr...|[world wide web, ...|[53e9b04eb7602d97...|       360|     361|  en|10.1145/2594368.2...|[http://dx.doi.or...|Yalut is a novel ...|      Conference|2009-02-24 08:00:34|\n",
      "|53e99792b7602d970...|A Uniform Paralle...|[knowledge discov...|[data mining, dat...|[53e99cbbb7602d97...|       306|     312|  en|10.1007/978-3-540...|[http://dx.doi.or...|Grid is a new sol...|         Journal|2015-02-28 22:51:57|\n",
      "|53e99792b7602d970...|WAVELET-BASED IMA...|[mathematical mod...|[computer vision,...|[53e9b550b7602d97...|      1737|    1740|  en|10.1109/ICIP.2010...|[http://dx.doi.or...|Because digital i...|      Conference|2005-12-16 23:43:26|\n",
      "|53e99792b7602d970...|A fuzzy multi-obj...|[location, fire s...|[objective progra...|[53e9bd50b7602d97...|       903|     915|  en|10.1016/j.ejor.20...|[http://dx.doi.or...|Location of fire ...|         Journal|1971-12-17 16:55:38|\n",
      "|53e99792b7602d970...|Adaptive presenta...|[evolving informa...|[metadata, progra...|[53e9a2c8b7602d97...|       193|     196|  en|10.1109/ICALT.200...|[http://dx.doi.or...|The article descr...|            Book|2011-05-08 17:41:02|\n",
      "|53e99792b7602d970...|Testing the stabi...|[asymptotic justi...|[functional princ...|[53e9ace1b7602d97...|       352|     367|  en|10.1016/j.jmva.20...|[http://dx.doi.or...|The functional au...|         Journal|1984-05-13 13:56:58|\n",
      "|53e99792b7602d970...|Statistical Prope...|[power cables, po...|[topology, trippi...|[53e9a7ddb7602d97...|      2517|    2526|  en|10.1109/HICSS.201...|[http://dx.doi.or...|We present the sy...|      Conference|2018-08-18 19:58:00|\n",
      "|53e99792b7602d970...|Generating novel ...|[adaptive behavio...|[interactive evol...|[53e9bc80b7602d97...|         8|      14|  en|10.1145/1056754.1...|[http://dx.doi.or...|Simulated evoluti...|         Journal|2021-05-05 05:11:38|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------+----+--------------------+--------------------+--------------------+----------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# PAPER TABLE WITHOUT PUBLICATION_ID\n",
    "schemaPaper = StructType(\n",
    "            [StructField('_id', StringType(), True),\n",
    "             StructField('title', StringType(),True),\n",
    "             StructField('keywords', ArrayType(StringType()), True),\n",
    "             StructField('fos', ArrayType(StringType()), True),\n",
    "             StructField('references', ArrayType(StringType()), True),\n",
    "             StructField('page_start', IntegerType(), True),\n",
    "             StructField('page_end', IntegerType(), True),\n",
    "             StructField('lang', StringType(),True),\n",
    "             StructField('doi', StringType(),True),\n",
    "             StructField('url', ArrayType(StringType()),True),\n",
    "             StructField('abstract', StringType(),True),\n",
    "             StructField('publication_type', StringType(),True),\n",
    "             StructField('date', TimestampType(), True)\n",
    "            ])\n",
    "\n",
    "df_paper = spark.read.format('json').options(**OPTIONS).schema(schemaPaper).json(INPUT_FILE)\n",
    "df_paper = df_paper.withColumnRenamed(\"_id\", \"paper_id\")\n",
    "df_paper.printSchema()\n",
    "df_paper.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- paper_id: string (nullable = true)\n",
      " |-- author_id: string (nullable = true)\n",
      " |-- organization: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 69:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|            paper_id|           author_id|        organization|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|53e998c7b7602d970...|53f3186fdabfae9a8...|Department of Sta...|\n",
      "|53e99827b7602d970...|53f3186fdabfae9a8...|Laboratory for Fo...|\n",
      "|53e99924b7602d970...|53f31870dabfae9a8...|Henan Academy of ...|\n",
      "|53e998dbb7602d970...|53f31871dabfae9a8...|Instituto de Físi...|\n",
      "|53e998f6b7602d970...|53f31873dabfae9a8...|                null|\n",
      "|53e998bfb7602d970...|53f31874dabfae9a8...|                null|\n",
      "|53e9984bb7602d970...|53f31875dabfae9a8...|                null|\n",
      "|53e998e8b7602d970...|53f31878dabfae9a8...|George Mason Univ...|\n",
      "|53e99905b7602d970...|53f3187ddabfae9a8...|State Key Laborat...|\n",
      "|53e998e9b7602d970...|53f31881dabfae9a8...|                null|\n",
      "|53e9984fb7602d970...|53f31881dabfae9a8...|Tecnologico de Mo...|\n",
      "|53e9980eb7602d970...|53f31883dabfae9a8...|University of Was...|\n",
      "|53e997e9b7602d970...|53f31885dabfae9a8...|Digital Equipment...|\n",
      "|53e998b0b7602d970...|53f31887dabfae9a8...|Antai College of ...|\n",
      "|53e998cdb7602d970...|53f31887dabfae9a8...|Department of Ind...|\n",
      "|53e998f0b7602d970...|53f3188adabfae9a8...|E-Gov, Juridical ...|\n",
      "|53e998fcb7602d970...|53f31892dabfae9a8...|2250 G G Brown, A...|\n",
      "|53e99998b7602d970...|53f31892dabfae9a8...|Chonnam National ...|\n",
      "|53e99800b7602d970...|53f31893dabfae9a8...|IBM Systems Resea...|\n",
      "|53e99866b7602d970...|53f3189ddabfae9a8...|Department of Mat...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# AFFILIATION TABLE\n",
    "schemaAffiliation = StructType(\n",
    "            [StructField('_id', StringType(), True),\n",
    "             StructField('authors', ArrayType(StructType([\n",
    "                    StructField('_id', StringType(), True),\n",
    "                    StructField('org', StringType(), True)\n",
    "             ])), True),\n",
    "            ])\n",
    "\n",
    "df_aff = spark.read.format('json').options(**OPTIONS).schema(schemaAffiliation).json(INPUT_FILE)\n",
    "df_aff = df_aff.withColumnRenamed(\"_id\", \"paper_id\")\n",
    "df_aff = df_aff.select(\"paper_id\", explode(df_aff.authors))\n",
    "df_aff = df_aff.withColumnRenamed(\"col\", \"authors\")\n",
    "df_aff = df_aff.filter(col(\"authors._id\") != \"null\").filter(col(\"paper_id\") != \"null\").select(\"paper_id\", \"authors._id\",\"authors.org\")\n",
    "df_aff = df_aff.withColumnRenamed(\"_id\", \"author_id\")\n",
    "df_aff = df_aff.dropDuplicates([\"author_id\", \"paper_id\"])\n",
    "df_aff = df_aff.withColumnRenamed(\"org\", \"organization\")\n",
    "df_aff.printSchema()\n",
    "df_aff.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema of the journals\n",
      "root\n",
      " |-- venue: string (nullable = true)\n",
      " |-- volume: integer (nullable = true)\n",
      " |-- issue: integer (nullable = true)\n",
      " |-- publisher: string (nullable = true)\n",
      " |-- issn: string (nullable = true)\n",
      " |-- publication_id: long (nullable = false)\n",
      "\n",
      "Journals\n",
      "+-----------------------+------+-----+------------------------------------------------------------------+---------+--------------------+\n",
      "|venue                  |volume|issue|publisher                                                         |issn     |publication_id      |\n",
      "+-----------------------+------+-----+------------------------------------------------------------------+---------+--------------------+\n",
      "|4OR                    |2     |4    |Inderscience Publishers                                           |1614-2411|-8668689828003778653|\n",
      "|4OR                    |3     |1    |Accent Social and Welfare Society                                 |1614-2411|-6055461944651662439|\n",
      "|4OR                    |4     |1    |Innovative Information Science & Technology Research Group (ISYOU)|1614-2411|4482587362010925183 |\n",
      "|4OR                    |4     |3    |Elsevier                                                          |1614-2411|-5369333412851545957|\n",
      "|4OR                    |6     |2    |John Wiley & Sons Inc.                                            |1614-2411|4907811008184705540 |\n",
      "|4OR                    |6     |4    |Elsevier                                                          |1614-2411|-7478992719207099405|\n",
      "|4OR                    |7     |2    |Taylor and Francis Ltd.                                           |1614-2411|-5578571051264951046|\n",
      "|4OR                    |8     |2    |Intellect Ltd.                                                    |1614-2411|3303577774132183121 |\n",
      "|4OR                    |8     |4    |Springer London                                                   |1614-2411|-3839102222582550984|\n",
      "|4OR                    |11    |2    |IOP Publishing Ltd.                                               |1614-2411|-8848711838540298032|\n",
      "|A retargetable debugger|27    |7    |IEEE Computer Society                                             |0362-1340|5898809803706162287 |\n",
      "|AAAI                   |21    |12   |Hindawi Publishing Corporation                                    |1041-4347|226561117377407236  |\n",
      "|AAIM                   |106   |4    |AGH University of Science and Technology                          |0020-0190|-1537115915808707536|\n",
      "|ACL                    |95    |3    |Wiley-Blackwell Publishing Ltd                                    |0885-6125|6922825622688887655 |\n",
      "|ACM Comput. Surv.      |10    |4    |Intellect Ltd.                                                    |0360-0300|-4352573166015971962|\n",
      "|ACM Comput. Surv.      |15    |3    |Elsevier                                                          |0360-0300|7493946580737751003 |\n",
      "|ACM Comput. Surv.      |15    |4    |Universidad Internacional de la Rioja                             |0360-0300|7340232518232887060 |\n",
      "|ACM Comput. Surv.      |16    |3    |Technischen Universitat Braunschweig                              |0360-0300|-7713800651548746073|\n",
      "|ACM Comput. Surv.      |18    |4    |Springer London                                                   |0360-0300|-7000780314495031015|\n",
      "|ACM Comput. Surv.      |27    |1    |Wiley-Blackwell Publishing Ltd                                    |0360-0300|-7255461002200856409|\n",
      "+-----------------------+------+-----+------------------------------------------------------------------+---------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# JOURNAL TABLE\n",
    "# Preprocessing of the journals for cleaning and merging the journals\n",
    "\n",
    "journal_schema_preprocessing = StructType(\n",
    "    [StructField('_id', StringType(), True),\n",
    "     StructField('issn', StringType(), True),\n",
    "     StructField('publisher', StringType(), True),\n",
    "     StructField('venue', StringType(), True),\n",
    "     StructField('volume', IntegerType(), True),\n",
    "     StructField('issue', IntegerType(), True),\n",
    "     StructField('publication_type', StringType(),True)])\n",
    "\n",
    "# Reading the json file\n",
    "df_journals_to_filter = spark.read.format('json').options(**OPTIONS).schema(journal_schema_preprocessing).json(INPUT_FILE)\n",
    "\n",
    "# Filtering and adjusting the dataframe\n",
    "df_journals_to_filter = df_journals_to_filter.filter(col('publication_type') == 'Journal').filter(col('issn') != 'null').filter(col('venue') != 'null').filter(col('issue') >= 0).filter(col('volume') >= 0)\n",
    "df_journals_to_filter = df_journals_to_filter.groupBy('venue', 'volume', 'issue', 'issn').agg(collect_list('publisher').alias('publishersArray'), collect_list('_id').alias('_id'), count(col('publisher'))) # count can be removed (I was interested in evaluating if the group by was meaningful)\n",
    "df_journals_to_insert = df_journals_to_filter.withColumn('publisher', df_journals_to_filter['publishersArray'][0]).select('venue', 'volume', 'issue', 'publisher', 'issn', '_id')\n",
    "\n",
    "# Adding the new column which contains the publication_identifier\n",
    "df_journals = df_journals_to_insert.withColumn(\"publication_id\", xxhash64('venue', 'volume', 'issue', 'issn'))\n",
    "\n",
    "# Adding the foreign key to the papers\n",
    "exploded_journals = df_journals.select(explode('_id'), 'publication_id')\n",
    "#exploded_journals.show(truncate = False)\n",
    "\n",
    "df_papers_in_journals = exploded_journals.join(df_paper, exploded_journals.col == df_paper.paper_id, \"inner\")\n",
    "df_papers_in_journals = df_papers_in_journals.drop('col')\n",
    "\n",
    "df_journals = df_journals.drop(df_journals._id)\n",
    "\n",
    "# Visualizing the data\n",
    "# print('Papers')\n",
    "# df_papers_in_journals.show(truncate = False)\n",
    "print('Schema of the journals')\n",
    "df_journals.printSchema()\n",
    "print('Journals')\n",
    "df_journals.show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema of the books\n",
      "root\n",
      " |-- venue: string (nullable = true)\n",
      " |-- isbn: string (nullable = true)\n",
      " |-- publisher: string (nullable = true)\n",
      " |-- publication_id: long (nullable = false)\n",
      "\n",
      "Books\n",
      "+------------------------------------------------------------------------------------+-------------+--------------------------------------------------+--------------------+\n",
      "|venue                                                                               |isbn         |publisher                                         |publication_id      |\n",
      "+------------------------------------------------------------------------------------+-------------+--------------------------------------------------+--------------------+\n",
      "|ACM SIGSOFT Software Engineering Notes                                              |-159593-125-2|AGH University of Science and Technology          |-4146681027596907540|\n",
      "|Theor. Comput. Sci.                                                                 |0-0304-3975  |Elsevier                                          |-8641604748836216424|\n",
      "|ACL (Companion)                                                                     |0-111-456789 |Intellect Ltd.                                    |-1765624198251536382|\n",
      "|VLDB                                                                                |0-12-088469-0|The American Society of Mechanical Engineers(ASME)|-6546099223240010863|\n",
      "|Papers from the second workshop Vol. 13 on Human and Machine Vision II              |0-12-597345-4|SpringerOpen                                      |-5170613698490267273|\n",
      "|VLDB                                                                                |0-12-722442-4|Open Library of Humanities                        |5803877754064281982 |\n",
      "|Artif. Intell. Rev.                                                                 |0-13-176751-8|World Scientific Publishing Co. Pte Ltd           |-5191022792199354246|\n",
      "|SFCS '85 Proceedings of the 26th Annual Symposium on Foundations of Computer Science|0-13-652017-0|Elsevier                                          |4898287511903231544 |\n",
      "|CHI                                                                                 |0-201-30987-4|AGH University of Science and Technology          |4745093320936461129 |\n",
      "|Computer Human Interaction                                                          |0-201-30987-4|Brown University                                  |-3213114594400519435|\n",
      "|SIGGRAPH                                                                            |0-201-48560-5|Springer Science + Business Media                 |7678090193378385384 |\n",
      "|CHI                                                                                 |0-201-50932-6|Elsevier                                          |22285894483278744   |\n",
      "|Sigplan Notices                                                                     |0-201-53372-3|Elsevier                                          |127134876966261428  |\n",
      "|ISSAC                                                                               |0-201-54892-5|Taylor and Francis Ltd.                           |-1355898789984227595|\n",
      "|History of programming languages---II                                               |0-201-89502-1|Springer Verlag                                   |-2667848576388063536|\n",
      "|Neural Networks                                                                     |0-262-03188-4|Elsevier                                          |4141971837342876240 |\n",
      "|Computational Statistics                                                            |0-262-10076-2|Springer Science + Business Media                 |-619826641325096993 |\n",
      "|Symposium on Programming Language Implementation and Logic Programming              |0-262-19297-7|Elsevier                                          |6701520537364205852 |\n",
      "|AAAI                                                                                |0-262-51057-X|Tsinghua University Press                         |1804946402782986900 |\n",
      "|Artif. Intell.                                                                      |0-262-51091-X|Editorial and Publishing Board of JIG             |529998888475133215  |\n",
      "+------------------------------------------------------------------------------------+-------------+--------------------------------------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# BOOK TABLE\n",
    "# Preprocessing of the books for cleaning and merging the books\n",
    "book_schema_preprocessing = StructType(\n",
    "    [StructField('_id', StringType(), True),\n",
    "     StructField('isbn', StringType(), True),\n",
    "     StructField('publisher', StringType(), True),\n",
    "     StructField('venue', StringType(), True),\n",
    "     StructField('publication_type', StringType(),True)])\n",
    "\n",
    "# Reading the json file\n",
    "df_books_to_filter = spark.read.format('json').options(**OPTIONS).schema(book_schema_preprocessing).json(INPUT_FILE)\n",
    "\n",
    "# Filtering and adjusting the dataframe\n",
    "df_books_to_filter = df_books_to_filter.filter(col('publication_type') == 'Book').filter(col('isbn') != 'null').filter(col('venue') != 'null')\n",
    "df_books_to_filter = df_books_to_filter.groupBy('isbn', 'venue').agg(collect_list('publisher').alias('publishersArray'), collect_list('_id').alias('_id'), count(col('publisher'))) # count can be removed (I was interested in evaluating if the group by was meaningful)\n",
    "dfbooks_to_insert = df_books_to_filter.withColumn('publisher', df_books_to_filter['publishersArray'][0]).select('venue', 'isbn', 'publisher', '_id')\n",
    "\n",
    "# Adding the new column which is the id\n",
    "df_books = dfbooks_to_insert.withColumn('publication_id', xxhash64('isbn', 'venue'))\n",
    "\n",
    "# Adding the foreign key to the papers\n",
    "exploded_books = df_books.select(explode('_id'), 'publication_id')\n",
    "# exploded_books.show(truncate = False)\n",
    "\n",
    "df_papers_in_books = exploded_books.join(df_paper, exploded_books.col == df_paper.paper_id)\n",
    "df_papers_in_books = df_papers_in_books.drop('col')\n",
    "\n",
    "df_books = df_books.drop(df_books._id)\n",
    "\n",
    "# Visualizing the data\n",
    "# print('Papers')\n",
    "# df_papers_in_books.show(truncate = False)\n",
    "print('Schema of the books')\n",
    "df_books.printSchema()\n",
    "print('Books')\n",
    "df_books.show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema of the conferences\n",
      "root\n",
      " |-- venue: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- publication_id: long (nullable = false)\n",
      "\n",
      "Conferences\n",
      "+----------------------------------------------------------------------------------------+--------------------------+--------------------+\n",
      "|venue                                                                                   |location                  |publication_id      |\n",
      "+----------------------------------------------------------------------------------------+--------------------------+--------------------+\n",
      "|\"EDUCON                                                                                 |Moscow, Russia            |950373860555954453  |\n",
      "|2012 50TH ANNUAL ALLERTON CONFERENCE ON COMMUNICATION, CONTROL, AND COMPUTING (ALLERTON)|Dublin, Ireland           |-4245717996156385657|\n",
      "|2985415099                                                                              |Mexico City, Mexico       |-762166203857654039 |\n",
      "|2985532720                                                                              |Milan, Italy              |-7124098142925130015|\n",
      "|2987493177                                                                              |Osaka, Japan              |7551243357793819285 |\n",
      "|3D-GIS                                                                                  |London, UK                |1334491883820369589 |\n",
      "|3DIM                                                                                    |Johannesburg, South Africa|-1039299792543803944|\n",
      "|3DIMPVT                                                                                 |Helsinki, Finland         |-4577231382119670667|\n",
      "|3DOR                                                                                    |London, UK                |-8797854120325021263|\n",
      "|3DPVT                                                                                   |Amsterdam, Netherlands    |1375276120944605061 |\n",
      "|3DUI                                                                                    |Seoul, South Korea        |1791021788110955539 |\n",
      "|3DV                                                                                     |Jakarta, Indonesia        |3883608681790763346 |\n",
      "|3PGCIC                                                                                  |Beijing, China            |-3347673940037205862|\n",
      "|50 Years of Integer Programming                                                         |London, UK                |-5154516725105661246|\n",
      "|AAMAS                                                                                   |Milan, Italy              |5503995461761334696 |\n",
      "|AAMAS (2)                                                                               |Paris, France             |-7242857281816016648|\n",
      "|ACAI                                                                                    |Toronto, Canada           |8524679771896464283 |\n",
      "|ACC'09 Proceedings of the 2009 conference on American Control Conference                |Beijing, China            |-3525577454028830485|\n",
      "|ACCV                                                                                    |London, UK                |8287527867910422941 |\n",
      "|ACCV (1)                                                                                |Tel Aviv, Israel          |-2757184551560203638|\n",
      "+----------------------------------------------------------------------------------------+--------------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CONFERENCE TABLE\n",
    "# Preprocessing of the books for cleaning and merging the books\n",
    "\n",
    "schemaConf = StructType(\n",
    "    [StructField('_id', StringType(), True),\n",
    "     StructField('location', StringType(), True),\n",
    "     StructField('venue', StringType(), True),\n",
    "     StructField('publication_type', StringType(),True)])\n",
    "# Reading the json file\n",
    "df_conferences_to_filter = spark.read.format('json').options(**OPTIONS).schema(schemaConf).json(INPUT_FILE)\n",
    "\n",
    "# Filtering and adjusting the dataframe\n",
    "df_conferences_to_filter = df_conferences_to_filter.filter(col('publication_type') == 'Conference').filter(col('venue') != 'null')\n",
    "df_conferences_to_filter = df_conferences_to_filter.groupBy('venue').agg(collect_list('location').alias('locations_array'), collect_list('_id').alias('_id'), count(col('location'))) # count can be removed (I was interested in evaluating if the group by was meaningful)\n",
    "df_conferences_to_insert = df_conferences_to_filter.withColumn('location', df_conferences_to_filter['locations_array'][0]).select('venue', 'location', '_id')\n",
    "\n",
    "# Adding the new column which is the id\n",
    "df_conferences = df_conferences_to_insert.withColumn('publication_id', xxhash64('venue'))\n",
    "\n",
    "# Adding the foreign key to the papers\n",
    "exploded_conferences = df_conferences.select(explode('_id'), 'publication_id')\n",
    "#exploded_conferences.show(truncate = False)\n",
    "\n",
    "df_papers_in_conferences = exploded_conferences.join(df_paper, exploded_conferences.col == df_paper.paper_id)\n",
    "df_papers_in_conferences = df_papers_in_conferences.drop('col')\n",
    "\n",
    "df_conferences = df_conferences.drop(df_conferences._id)\n",
    "\n",
    "# Visualizing the data\n",
    "#print('Papers')\n",
    "#df_papers_in_conferences.show(truncate = False)\n",
    "print('Schema of the conferences')\n",
    "df_conferences.printSchema()\n",
    "print('Conferences')\n",
    "df_conferences.show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Papers schema\n",
      "root\n",
      " |-- publication_id: long (nullable = false)\n",
      " |-- paper_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- keywords: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- fos: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- references: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- page_start: integer (nullable = true)\n",
      " |-- page_end: integer (nullable = true)\n",
      " |-- lang: string (nullable = true)\n",
      " |-- doi: string (nullable = true)\n",
      " |-- url: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- abstract: string (nullable = true)\n",
      " |-- publication_type: string (nullable = true)\n",
      " |-- date: timestamp (nullable = true)\n",
      "\n",
      "Papers data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 16:>                 (0 + 1) / 1][Stage 18:>                 (0 + 0) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------+----+--------------------+--------------------+--------------------+----------------+-------------------+\n",
      "|      publication_id|            paper_id|               title|            keywords|                 fos|          references|page_start|page_end|lang|                 doi|                 url|            abstract|publication_type|               date|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------+----+--------------------+--------------------+--------------------+----------------+-------------------+\n",
      "|-4336127124407324726|53e997d1b7602d970...|A fault diagnosis...|[stuck at defects...|[computer testing...|[53e9bca6b7602d97...|       494|     494|  en|10.1109/EDTC.1997...|[http://dx.doi.or...|In this paper we ...|            Book|1950-09-08 12:23:35|\n",
      "| 4674035537543784623|53e997e4b7602d970...|Problem Decomposi...|[problem decompos...|[inductive logic ...|[53e9a690b7602d97...|        17|      31|  en|10.1007/3-540-592...|[http://dx.doi.or...|One dimension of ...|            Book|1986-12-29 07:27:28|\n",
      "| 1144530160964015551|53e997e8b7602d970...|X-tract: Structur...|[information retr...|[information stru...|[53e9b0d8b7602d97...|         2|       2|  en|10.1109/SPIRE.199...|[http://computer....|Most available in...|            Book|1954-04-24 05:44:09|\n",
      "|-6465152039831803131|53e997e8b7602d970...|Cognitive agent p...|[dynamic logic, a...|[functional logic...|[53e9b38fb7602d97...|      1385|    1385|  en|10.1145/1082473.1...|[http://dx.doi.or...|This is a summary...|            Book|1992-05-16 17:49:48|\n",
      "| 5112790730981969721|53e997e9b7602d970...|Constraint based ...|[uniform framewor...|[computer science...|[53e9b326b7602d97...|       195|     204|  en|10.1145/318789.31...|[http://dx.doi.or...|The constraint tr...|            Book|1978-02-04 19:19:02|\n",
      "| 1369111316993402587|53e997ecb7602d970...|Automatic input r...|[google picasa, d...|[novel technique,...|[53e9a29db7602d97...|        80|      90|  en|10.1109/ICSE.2012...|[http://dx.doi.or...|We present a nove...|            Book|1971-08-25 11:47:59|\n",
      "| 1430384888819899512|53e997ecb7602d970...|Acceptability-ori...|[monitoring, acce...|[programming lang...|[53e9badfb7602d97...|        57|      75|  en|10.1145/966051.96...|[http://dx.doi.or...|We discuss a new ...|            Book|1964-08-09 22:48:00|\n",
      "|  710748220667054414|53e997ecb7602d970...|Anomalous Neighbo...|[column wise diff...|[mathematical opt...|[53e9a0a6b7602d97...|       474|     480|  en|10.1109/ICDMW.201...|[http://dx.doi.or...|We propose a meth...|            Book|1996-03-16 14:37:00|\n",
      "| 8148044123726554362|53e997f1b7602d970...|A Digital Watermark.|[authentication, ...|[computer vision,...|[53e99822b7602d97...|        86|      90|  en|10.1109/ICIP.1994...|[http://dx.doi.or...|This paper discus...|            Book|2001-12-04 20:38:24|\n",
      "|-8250923667053511275|53e997f4b7602d970...|Independent Tree ...|[independent tree...|[combinatorics, m...|[53e9b2f5b7602d97...|       203|     214|  en| 10.1007/10692760_17|[http://dx.doi.or...|\\n For any fixed ...|            Book|2014-02-26 04:06:46|\n",
      "| 8160813231728112221|53e997f5b7602d970...|Inverting onto fu...|[nondeterministic...|[computer science...|[53e9b4afb7602d97...|       213|     222|  en|10.1016/S0890-540...|[http://dx.doi.or...|We look at the hy...|            Book|2015-12-31 07:56:33|\n",
      "| 6712300784079919943|53e9980eb7602d970...|   EVES: An Overview|[never, formal me...|[programming lang...|[53e9a2bab7602d97...|       389|     405|  en|10.1007/3-540-548...|[http://dx.doi.or...|In this paper we ...|            Book|1972-08-07 17:35:34|\n",
      "|-1585425199704921662|53e99813b7602d970...|Distributed proba...|[error correction...|[binary pattern, ...|[53e99a67b7602d97...|      3398|    3401|  en|10.1109/ICASSP.20...|[http://dx.doi.or...|This paper introd...|            Book|2016-08-28 14:12:19|\n",
      "| 6134863903676584956|53e99818b7602d970...|Regulations by Va...|[power method, no...|[context sensitiv...|[53e9a946b7602d97...|       239|     248|  en|  10.1007/BFb0029967|[http://dx.doi.or...| . Valences are a...|            Book|1961-02-26 08:04:12|\n",
      "| 2530147181524079819|53e99818b7602d970...|Reflections on sy...|[object oriented,...|[communication de...|[53e99832b7602d97...|        28|      33|  en|10.1145/1556262.1...|[http://dx.doi.or...|Symmetry is routi...|            Book|2009-10-03 17:07:24|\n",
      "| 2735482298684145043|53e99827b7602d970...|Timestamping afte...|[committed transa...|[transaction proc...|[53e9b587b7602d97...|       160|     167|  en|10.1109/PDIS.1994...|[http://dx.doi.or...|Many applications...|            Book|1951-11-27 17:50:37|\n",
      "| 5744511372260825900|53e99827b7602d970...|The Animachine re...|[useful effect, v...|[3d computer grap...|[53e9ab2bb7602d97...|        90|      90|  en|10.1109/CA.1995.3...|[http://doi.ieeec...|Two-dimensional a...|            Book|2007-10-16 04:48:40|\n",
      "| 2483812910487536561|53e99827b7602d970...|     The CD1 system.|[advanced constra...|[sql, conceptual ...|[53e99967b7602d97...|         1|       9|  en|10.1007/978-3-642...|[http://dx.doi.or...|\\n We describe a ...|            Book|2013-03-31 03:16:37|\n",
      "| 8942054755879642437|53e9982cb7602d970...|Public-Key Regist...|[registration req...|[fixed access, cr...|[53e99a74b7602d97...|       451|     458|  en|10.1007/3-540-477...|[http://dx.doi.or...|A procedure is de...|            Book|1993-11-20 16:32:56|\n",
      "| 8730891231843712925|53e9983db7602d970...|Learning Automata...|[blue fringe edsm...|[quantum finite a...|[53e9afa6b7602d97...|        52|      65|  en|10.1007/978-3-642...|[http://dx.doi.or...|\\n We prove in th...|            Book|1960-12-16 13:42:14|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------+----+--------------------+--------------------+--------------------+----------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Merging the 3 dataframe which one contains the papers published in a specific media\n",
    "df_papers = df_papers_in_books.union(df_papers_in_journals).union(df_papers_in_conferences)\n",
    "\n",
    "# Visualizing the data\n",
    "print('Papers schema')\n",
    "df_papers.printSchema()\n",
    "print('Papers data')\n",
    "df_papers.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Papers published in books\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------------+--------------------+\n",
      "|            paper_id|               title|publication_type|      publication_id|\n",
      "+--------------------+--------------------+----------------+--------------------+\n",
      "|53e997d1b7602d970...|A fault diagnosis...|            Book|-4336127124407324726|\n",
      "|53e997e4b7602d970...|Problem Decomposi...|            Book| 4674035537543784623|\n",
      "|53e997e8b7602d970...|X-tract: Structur...|            Book| 1144530160964015551|\n",
      "|53e997e8b7602d970...|Cognitive agent p...|            Book|-6465152039831803131|\n",
      "|53e997e9b7602d970...|Constraint based ...|            Book| 5112790730981969721|\n",
      "|53e997ecb7602d970...|Automatic input r...|            Book| 1369111316993402587|\n",
      "|53e997ecb7602d970...|Acceptability-ori...|            Book| 1430384888819899512|\n",
      "|53e997ecb7602d970...|Anomalous Neighbo...|            Book|  710748220667054414|\n",
      "|53e997f1b7602d970...|A Digital Watermark.|            Book| 8148044123726554362|\n",
      "|53e997f4b7602d970...|Independent Tree ...|            Book|-8250923667053511275|\n",
      "|53e997f5b7602d970...|Inverting onto fu...|            Book| 8160813231728112221|\n",
      "|53e9980eb7602d970...|   EVES: An Overview|            Book| 6712300784079919943|\n",
      "|53e99813b7602d970...|Distributed proba...|            Book|-1585425199704921662|\n",
      "|53e99818b7602d970...|Regulations by Va...|            Book| 6134863903676584956|\n",
      "|53e99818b7602d970...|Reflections on sy...|            Book| 2530147181524079819|\n",
      "|53e99827b7602d970...|Timestamping afte...|            Book| 2735482298684145043|\n",
      "|53e99827b7602d970...|The Animachine re...|            Book| 5744511372260825900|\n",
      "|53e99827b7602d970...|     The CD1 system.|            Book| 2483812910487536561|\n",
      "|53e9982cb7602d970...|Public-Key Regist...|            Book| 8942054755879642437|\n",
      "|53e9983db7602d970...|Learning Automata...|            Book| 8730891231843712925|\n",
      "+--------------------+--------------------+----------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Papers published in journals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------------+--------------------+\n",
      "|            paper_id|               title|publication_type|      publication_id|\n",
      "+--------------------+--------------------+----------------+--------------------+\n",
      "|53e99915b7602d970...|A note on robust ...|         Journal|-8668689828003778653|\n",
      "|53e99984b7602d970...|A new approach fo...|         Journal|-6055461944651662439|\n",
      "|53e998b0b7602d970...|Two-machine flow ...|         Journal| 4482587362010925183|\n",
      "|53e9994cb7602d970...|Stochastic semide...|         Journal|-5369333412851545957|\n",
      "|53e9990db7602d970...|Models and algori...|         Journal| 4907811008184705540|\n",
      "|53e99952b7602d970...|Maximizing the mi...|         Journal|-7478992719207099405|\n",
      "|53e99800b7602d970...|Integer extended ...|         Journal|-5578571051264951046|\n",
      "|53e99858b7602d970...|Attraction probab...|         Journal| 3303577774132183121|\n",
      "|53e9998bb7602d970...|Strategy vs risk ...|         Journal|-3839102222582550984|\n",
      "|53e99915b7602d970...|A necessary 4-cyc...|         Journal|-8848711838540298032|\n",
      "|53e997f1b7602d970...|A retargetable de...|         Journal| 5898809803706162287|\n",
      "|53e997ddb7602d970...|Clustering with L...|         Journal|  226561117377407236|\n",
      "|53e99858b7602d970...|Weighted broadcas...|         Journal|-1537115915808707536|\n",
      "|53e997f4b7602d970...|Interactive topic...|         Journal| 6922825622688887655|\n",
      "|53e99991b7602d970...|Graphics Programm...|         Journal|-4352573166015971962|\n",
      "|53e99832b7602d970...|Program Transform...|         Journal| 7493946580737751003|\n",
      "|53e9984bb7602d970...|Voice response sy...|         Journal| 7340232518232887060|\n",
      "|53e9982cb7602d970...|Parallel graph al...|         Journal|-7713800651548746073|\n",
      "|53e99813b7602d970...|Dataflow machine ...|         Journal|-7000780314495031015|\n",
      "|53e997d1b7602d970...|Can there be a sc...|         Journal|-7255461002200856409|\n",
      "+--------------------+--------------------+----------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Papers published in conferences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 56:>   (0 + 1) / 1][Stage 58:>   (0 + 0) / 1][Stage 60:>   (0 + 0) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------------+--------------------+\n",
      "|            paper_id|               title|publication_type|      publication_id|\n",
      "+--------------------+--------------------+----------------+--------------------+\n",
      "|53e99854b7602d970...|  The EOLES project.|      Conference|  950373860555954453|\n",
      "|53e9989bb7602d970...|Life is engineeri...|      Conference|  950373860555954453|\n",
      "|53e998bfb7602d970...|Gaining and maint...|      Conference|  950373860555954453|\n",
      "|53e998c0b7602d970...|From manuals towa...|      Conference|  950373860555954453|\n",
      "|53e998e9b7602d970...|Learning with com...|      Conference|  950373860555954453|\n",
      "|53e99976b7602d970...|Cloud E-learning ...|      Conference|  950373860555954453|\n",
      "|53e9997eb7602d970...|Motivating progra...|      Conference|  950373860555954453|\n",
      "|53e99991b7602d970...|Monitoring studen...|      Conference|  950373860555954453|\n",
      "|53e99998b7602d970...|OLAREX project: O...|      Conference|  950373860555954453|\n",
      "|53e99859b7602d970...|Studying dynamic ...|      Conference|-4245717996156385657|\n",
      "|53e99860b7602d970...|Equivalence of br...|      Conference|-4245717996156385657|\n",
      "|53e998bfb7602d970...|Fish Schools: PDE...|      Conference| -762166203857654039|\n",
      "|53e9997eb7602d970...|Automatic Generat...|      Conference|-7124098142925130015|\n",
      "|53e998fdb7602d970...|Fault-Tolerant Sc...|      Conference| 7551243357793819285|\n",
      "|53e9990db7602d970...|Automatic Generat...|      Conference| 1334491883820369589|\n",
      "|53e99822b7602d970...|Stroboscopic Ster...|      Conference|-1039299792543803944|\n",
      "|53e998bfb7602d970...|Image-Based Techn...|      Conference|-1039299792543803944|\n",
      "|53e9991cb7602d970...|Scanning and Proc...|      Conference|-1039299792543803944|\n",
      "|53e99940b7602d970...|Range Image Regis...|      Conference|-1039299792543803944|\n",
      "|53e99937b7602d970...|Cage-Based Motion...|      Conference|-4577231382119670667|\n",
      "+--------------------+--------------------+----------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# For checking the result\n",
    "print('Papers published in books')\n",
    "df_papers.filter(col('publication_type') == 'Book').select('paper_id', 'title', 'publication_type', 'publication_id').show()\n",
    "print('Papers published in journals')\n",
    "df_papers.filter(col('publication_type') == 'Journal').select('paper_id', 'title', 'publication_type', 'publication_id').show()\n",
    "print('Papers published in conferences')\n",
    "df_papers.filter(col('publication_type') == 'Conference').select('paper_id', 'title', 'publication_type', 'publication_id').show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "COMMANDS"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Command 2:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+-------------------+\n",
      "|               title|publication_type|               date|\n",
      "+--------------------+----------------+-------------------+\n",
      "|Generalized one-u...|      Conference|1951-01-03 03:43:07|\n",
      "|Predicting PDZ do...|         Journal|1951-01-03 03:43:07|\n",
      "|A New EDI-based D...|         Journal|1951-01-03 03:43:07|\n",
      "|Search-based Exec...|      Conference|1951-01-03 03:43:07|\n",
      "|Multi-structural ...|         Journal|1951-01-03 03:43:07|\n",
      "|Corpus-based ling...|            Book|1951-01-03 03:43:07|\n",
      "|A comparative stu...|         Journal|1951-01-03 03:43:07|\n",
      "|Fast Solution of ...|         Journal|1951-01-03 03:43:07|\n",
      "|Local Hausdorff D...|         Journal|1951-01-03 03:43:07|\n",
      "|Grammatical Evolu...|            Book|1951-01-03 03:43:07|\n",
      "|Global optimizati...|         Journal|1951-01-03 03:43:07|\n",
      "|Processing UML Mo...|            Book|1951-01-03 03:43:07|\n",
      "|Balancing buffer ...|         Journal|1951-01-03 03:43:07|\n",
      "|The Animation of ...|            Book|1951-01-03 03:43:07|\n",
      "|Composing graphic...|      Conference|1951-01-03 03:43:07|\n",
      "|Locally bounded c...|         Journal|1951-01-31 14:29:19|\n",
      "|Robust observer d...|         Journal|1951-01-31 14:29:19|\n",
      "|Object-oriented f...|            Book|1951-01-31 14:29:19|\n",
      "|A CRT-based RSA c...|            Book|1951-01-31 14:29:19|\n",
      "|Agent-based auctions|            Book|1951-01-31 14:29:19|\n",
      "+--------------------+----------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Command 4: delete a group of rows\n",
    "\n",
    "# Use the function year to extract the year from the timestamp\n",
    "from pyspark.sql.functions import year\n",
    "\n",
    "# Drop rows with conditions – where clause\n",
    "# From 37626 to 37175 -> delete all the rows that represent papers published before 1950, because obsolete\n",
    "df_papers = df_papers.where(year('date') > '1950')\n",
    "df_papers.select('title', 'publication_type', 'date').orderBy('date').show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 87:>   (0 + 1) / 1][Stage 89:>   (0 + 0) / 1][Stage 91:>   (0 + 0) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------+----------+--------+-----------+\n",
      "|title                                                            |page_start|page_end|total_pages|\n",
      "+-----------------------------------------------------------------+----------+--------+-----------+\n",
      "|Problem Decomposition and the Learning of Skills                 |17        |31      |14         |\n",
      "|X-tract: Structure Extraction from Botanical Textual Descriptions|2         |2       |0          |\n",
      "|Cognitive agent programming                                      |1385      |1385    |0          |\n",
      "|Constraint based vectorization                                   |195       |204     |9          |\n",
      "|Automatic input rectification                                    |80        |90      |10         |\n",
      "+-----------------------------------------------------------------+----------+--------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Command 5: create a new column with the length of the paper (number of total pages)\n",
    "\n",
    "df_papers_total_pages = df_papers \\\n",
    "    .filter((col('page_start') >= 0) & (col('page_end') >= 0) & (col('page_start') <= col('page_end'))) \\\n",
    "    .withColumn('total_pages', col('page_end') - col('page_start'))\n",
    "\n",
    "df_papers_total_pages \\\n",
    "    .select(col('title'), col('page_start'), col('page_end'), col('total_pages')) \\\n",
    "    .show(5, truncate=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "QUERIES"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 100:>  (0 + 1) / 1][Stage 102:>  (0 + 0) / 1][Stage 104:>  (0 + 0) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+------------------------------------------------------------+\n",
      "|                paper_id|                                                       title|\n",
      "+------------------------+------------------------------------------------------------+\n",
      "|53e997f4b7602d9701ff55f7|BioCause: Annotating and analysing causality in the biome...|\n",
      "|53e99860b7602d970209d6b9|Predicting PDZ domain mediated protein interactions from ...|\n",
      "|53e99867b7602d97020a2868|Jimena: efficient computing and system state identificati...|\n",
      "|53e9989bb7602d97020d129a|Reconciliation-based detection of co-evolving gene families.|\n",
      "|53e998c7b7602d97021001f0|SeqSIMLA: a sequence and phenotype simulation tool for co...|\n",
      "|53e998cdb7602d97021066c0|Cheminformatic models based on machine learning for pyruv...|\n",
      "|53e99938b7602d9702177171|SynTView - an interactive multi-view genome browser for n...|\n",
      "|53e99953b7602d970219688f|CoMAGC: a corpus with multi-faceted annotations of gene-c...|\n",
      "|53e9998bb7602d97021d0801|Large-scale extraction of accurate drug-disease treatment...|\n",
      "+------------------------+------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Query 1: WHERE, JOIN\n",
    "\n",
    "venue, volume, issue = ('BMC Bioinformatics', '14', '1') \n",
    "\n",
    "df_papers_q1 = df_journals\\\n",
    "               .filter((col('venue') == venue) &\n",
    "                       (col('volume') == volume) &\n",
    "                       (col('issue') == issue))\\\n",
    "                .join(df_papers,\n",
    "                      (df_journals['publication_id'] == df_papers['publication_id']) &\n",
    "                        (df_papers['publication_type'] == 'Journal')\n",
    "                     )\n",
    "\n",
    "df_papers_q1.select(['paper_id', 'title']).show(truncate=60)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------+-------------------+-----------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|title                                                                                          |date               |keyword                                                                                                                                        |\n",
      "+-----------------------------------------------------------------------------------------------+-------------------+-----------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Evolved swarming without positioning information: an application in aerial communication relay |1951-02-02 18:36:03|artificial evolution                                                                                                                           |\n",
      "|Evolved swarming without positioning information: an application in aerial communication relay |1951-02-02 18:36:03|swarm intelligence swarming without positioning micro air vehicles mavs communication relay artificial evolution situated communication smavnet|\n",
      "|NeuroFPGA -- Implementing Artificial Neural Networks on Programmable Logic Devices             |1951-03-08 02:45:20|artificial neural network                                                                                                                      |\n",
      "|NeuroFPGA -- Implementing Artificial Neural Networks on Programmable Logic Devices             |1951-03-08 02:45:20|implementing artificial neural networks                                                                                                        |\n",
      "|Wang Notation Tool: Layout independent representation of tables                                |1951-03-08 02:45:20|ontologies artificial intelligence                                                                                                             |\n",
      "|Variability in Behavior of Command Agents with Human-Like Decision Making Strategies           |1951-04-12 23:40:04|artificial intelligence                                                                                                                        |\n",
      "|Semantic Filtering in Social Media for Trend Modeling                                          |1951-04-13 01:32:11|learning artificial intelligence                                                                                                               |\n",
      "|A stochastic viewpoint on the generation of spatiotemporal datasets                            |1951-05-07 14:04:46|artificial datasets                                                                                                                            |\n",
      "|Enforceable social laws                                                                        |1951-07-06 05:46:48|artificial social system                                                                                                                       |\n",
      "|Enforceable social laws                                                                        |1951-07-06 05:46:48|artificial social systems                                                                                                                      |\n",
      "|Engineering Drug Design Using a Multi-Input Multi-Output Neuro-Fuzzy System                    |1951-07-25 19:20:07|learning artificial intelligence                                                                                                               |\n",
      "|Engineering Drug Design Using a Multi-Input Multi-Output Neuro-Fuzzy System                    |1951-07-25 19:20:07|artificial neural network                                                                                                                      |\n",
      "|Development of a knowledge-based system for monitoring and diagnosis of the CO2 capture process|1951-07-25 19:20:07|artificial intelligence techniques                                                                                                             |\n",
      "|Image Attribute Adaptation                                                                     |1951-07-25 19:20:07|learning artificial intelligence                                                                                                               |\n",
      "|Image Attribute Adaptation                                                                     |1951-07-25 19:20:07|ontologies artificial intelligence                                                                                                             |\n",
      "|Template based evolution                                                                       |1951-08-30 13:01:12|artificial creature                                                                                                                            |\n",
      "|Heuristic Method for Discriminative Structure Learning of Markov Logic Networks                |1951-09-06 15:17:17|learning artificial intelligence                                                                                                               |\n",
      "|A Dynamic Service Level Negotiation Mechanism for QoS Provisioning in NGEO Satellite Networks  |1951-09-11 17:11:44|artificial satellites                                                                                                                          |\n",
      "|Learning bimanual coordination patterns for rhythmic movements                                 |1951-09-11 17:11:44|artificial system                                                                                                                              |\n",
      "|A microworld approach to the formalization of musical knowledge                                |1951-09-11 17:11:44|artificial intelligence and music                                                                                                              |\n",
      "+-----------------------------------------------------------------------------------------------+-------------------+-----------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import current_timestamp, unix_timestamp\n",
    "# Query 2: WHERE, LIMIT, LIKE\n",
    "# Find the papers written in the last twenty years in english whose keywords have the word \\verb|artificial| inside the keywords. We require that these papers have the DOI set to a not null value.\n",
    "# The results are ordered ascendengly by the date and only 20 elements are printed.\n",
    "\n",
    "df = df_papers.withColumn('current time', current_timestamp())\n",
    "df = df\\\n",
    "    .filter(\n",
    "        (((unix_timestamp('current time') - unix_timestamp('date')) / 3600 / 24 / 365) > 50) & \n",
    "        (col('doi').isNotNull()))\\\n",
    "    .select('title', 'date', explode('keywords').alias('keyword'))\\\n",
    "    .filter(col('keyword').like('%artificial%'))\\\n",
    "    .distinct()\\\n",
    "    .sort(col('date').asc())\\\n",
    "    .limit(20)\\\n",
    "    .show(truncate = False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------+--------------------------------------------------+\n",
      "|                                      organization|                                            papers|\n",
      "+--------------------------------------------------+--------------------------------------------------+\n",
      "|        Carnegie Mellon University, Pittsburgh, PA|[53e998dbb7602d9702118f29, 53e9987db7602d97020b...|\n",
      "|   Carnegie Mellon University, Pittsburgh, PA, USA|[53e998c7b7602d97020fdf46, 53e99905b7602d970214...|\n",
      "| Georgia Institute of Technology, Atlanta, GA, USA|[53e99827b7602d9702048d5f, 53e998f6b7602d970213...|\n",
      "|           Microsoft Research Asia, Beijing, China|[53e99976b7602d97021b91db, 53e9980eb7602d970202...|\n",
      "|              Microsoft Research, Redmond, WA, USA|[53e99885b7602d97020bfe89, 53e99930b7602d970216...|\n",
      "|National University of Singapore, Singapore, Si...|[53e99813b7602d970202da43, 53e99876b7602d97020b...|\n",
      "|               Tsinghua University, Beijing, China|[53e998c7b7602d97020fdf46, 53e99998b7602d97021d...|\n",
      "|        University of Washington, Seattle, WA, USA|[53e998aab7602d97020e600e, 53e99967b7602d97021a...|\n",
      "+--------------------------------------------------+--------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query 4: GROUP BY, JOIN, AS\n",
    "from pyspark.sql.functions import collect_set, size\n",
    "\n",
    "df = df_aff\\\n",
    "    .join(df_papers, df_papers.paper_id == df_aff.paper_id, 'inner')\\\n",
    "    .drop(df_papers.paper_id).select('paper_id', 'organization', 'publication_type')\\\n",
    "    .filter((col('organization').isNotNull()) & (col('organization') != \"\") & (col('publication_type') == \"Conference\"))\\\n",
    "    .groupBy('organization')\\\n",
    "    .agg(collect_set('paper_id').alias('papers'))\\\n",
    "    .filter(size(col('papers')) > 10)\\\n",
    "    .show(truncate = 50)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+-----------+---------+---------+---------+---------+\n",
      "|year|total_papers|total_pages|min_pages|max_pages|avg_pages|var_pages|\n",
      "+----+------------+-----------+---------+---------+---------+---------+\n",
      "|2022|         289|       2918|        0|       41|    10.10|    47.79|\n",
      "|2021|         455|       5881|        0|     1585|    12.93| 5,509.97|\n",
      "|2020|         556|       5345|        0|      145|     9.61|    94.19|\n",
      "|2019|         459|       4334|        0|      135|     9.44|    80.38|\n",
      "|2018|         504|       4756|        0|      135|     9.44|    74.82|\n",
      "|2017|         423|       3818|        0|       49|     9.03|    50.92|\n",
      "|2016|         728|       6687|        0|       55|     9.19|    45.74|\n",
      "|2015|         530|       5364|        0|      158|    10.12|    92.43|\n",
      "+----+------------+-----------+---------+---------+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query 5: WHERE, GROUP BY\n",
    "# Retrieve some statistics about papers\n",
    "from pyspark.sql.functions import sum, min, max, avg, format_number, variance\n",
    "\n",
    "df_papers_total_pages.filter(year(col('date')) >= 2015) \\\n",
    "    .groupBy(year(col('date')).alias('year')) \\\n",
    "    .agg(count('paper_id').alias('total_papers'),\n",
    "         sum('total_pages').alias('total_pages'),\n",
    "         min('total_pages').alias('min_pages'),\n",
    "         max('total_pages').alias('max_pages'),\n",
    "         format_number(avg('total_pages'), 2).alias('avg_pages'),\n",
    "         format_number(variance('total_pages'), 2).alias('var_pages')) \\\n",
    "    .sort(col('year').desc()) \\\n",
    "    .show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------+----------------+\n",
      "|title                                                            |references_count|\n",
      "+-----------------------------------------------------------------+----------------+\n",
      "|Distinctive Image Features from Scale-Invariant Keypoints        |195             |\n",
      "|A simple transmit diversity technique for wireless communications|62              |\n",
      "|Light field rendering                                            |56              |\n",
      "|Network information flow                                         |55              |\n",
      "|Mining Sequential Patterns                                       |44              |\n",
      "|Symbolic Model Checking                                          |44              |\n",
      "|Geodesic Active Contour.                                         |40              |\n",
      "|Differential Power Analysis                                      |38              |\n",
      "+-----------------------------------------------------------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query 6: GROUP BY, HAVING, AS\n",
    "\n",
    "df_papers_q6 = df_papers\\\n",
    "               .select('paper_id',\n",
    "                       'title',\n",
    "                       explode(col('references')).alias('reference'))\\\n",
    "               .groupBy('reference')\\\n",
    "               .agg(count('paper_id').alias('references_count'))\\\n",
    "               .filter(col('references_count') > 30)\\\n",
    "               .join(df_papers,\n",
    "                     col('reference') == df_papers.paper_id)\\\n",
    "               .sort(col('references_count').desc())\\\n",
    "\n",
    "df_papers_q6.select(['title', 'references_count']).show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# Query 7: WHERE, GROUP BY, HAVING, AS\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 202:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------+--------------------------------------------------+\n",
      "|                                publisher|                  total_publications_per_publisher|\n",
      "+-----------------------------------------+--------------------------------------------------+\n",
      "|                  Taylor and Francis Ltd.|[Special Interest Group on Software Engineering...|\n",
      "|                                 Elsevier|[SAS, VAST, Focus on Scientific Visualization, ...|\n",
      "|Association for Computing Machinery (ACM)|[Special Interest Group on Software Engineering...|\n",
      "|                          Springer Verlag|[IEEE METRICS, ISQED, Special Interest Group on...|\n",
      "+-----------------------------------------+--------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Query 9: WHERE, GROUP BY, HAVING, 1 JOIN\n",
    "\n",
    "from pyspark.sql.functions import collect_set, concat, size\n",
    "\n",
    "df = df_journals\\\n",
    "    .withColumnRenamed('venue', 'venueJournals')\\\n",
    "    .filter((col('volume')) > 10)\\\n",
    "    .join(df_books,df_books.publisher == df_journals.publisher,\"inner\")\\\n",
    "    .drop(df_journals.publisher)\\\n",
    "    .withColumnRenamed('venue', 'venueBooks')\\\n",
    "    .select('venueBooks', 'venueJournals', 'publisher')\\\n",
    "    .dropDuplicates(['venueBooks', 'venueJournals', 'publisher'])\\\n",
    "    .groupBy('publisher')\\\n",
    "    .agg(collect_set('venueBooks').alias('books'),\n",
    "         collect_set('venueJournals').alias('journals'))\\\n",
    "    .withColumn(\"total_publications_per_publisher\",\n",
    "                concat(col(\"books\"), col(\"journals\")))\\\n",
    "    .filter(size(col(\"total_publications_per_publisher\")) > '500')\\\n",
    "    .select('publisher', \"total_publications_per_publisher\")\\\n",
    "    .show(truncate = 50)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/08 22:46:57 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------+-------------------+\n",
      "|               name|papers_count|organizations_count|\n",
      "+-------------------+------------+-------------------+\n",
      "|   Rachid Guerraoui|          22|                 11|\n",
      "|Thomas A. Henzinger|          21|                 14|\n",
      "|        Dacheng Tao|          20|                 13|\n",
      "|     Moshe Y. Vardi|          20|                  7|\n",
      "|    Thomas S. Huang|          19|                 10|\n",
      "+-------------------+------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query 10: WHERE, GROUP BY, HAVING, 2 JOINs\n",
    "# Retrieve authors who worked for at least 3 different organizations and have published at least 3 papers with at least 5 fos and 5 references each\n",
    "\n",
    "from pyspark.sql.functions import approx_count_distinct\n",
    "\n",
    "df_papers \\\n",
    "    .filter((size(col('fos')) >= 5) & (size(col('references')) >= 5)) \\\n",
    "    .join(df_aff, df_papers.paper_id == df_aff.paper_id, \"inner\") \\\n",
    "    .drop(df_aff.paper_id) \\\n",
    "    .join(df_aut, df_aff.author_id == df_aut.author_id, \"inner\") \\\n",
    "    .drop(df_aff.author_id) \\\n",
    "    .groupBy(\"author_id\") \\\n",
    "    .agg(count(\"paper_id\").alias(\"papers_count\"),\n",
    "         approx_count_distinct(\"organization\").alias(\"organizations_count\"),\n",
    "         collect_set(\"name\").alias(\"name\")) \\\n",
    "    .filter((size(\"name\") == 1) & (col(\"papers_count\") >= 3)  & (col(\"organizations_count\") >= 3)) \\\n",
    "    .orderBy(col(\"papers_count\").desc(), col(\"organizations_count\").desc()) \\\n",
    "    .select(explode(col(\"name\")).alias(\"name\"), col(\"papers_count\"), col(\"organizations_count\")) \\\n",
    "    .show(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}